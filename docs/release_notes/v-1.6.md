# Airbyte 1.6

The Easter Bunny reports a shortage of eggs this year. Airbyte has plenty of new features, though, so we're cracking 🐣 open a new version just for you. Airbyte 1.6 was released on April 11, 2025. We're excited to share new improvements and changes to the Airbyte platform.

## 🚀 Platform changes

These changes improve Airbyte for everyone.

### Connection page dashboard

Connection pages now include a dashboard that visualizes sync successes and failures. This high-level view gives you quick insight into the health of your syncs over hours, days, and weeks. Track down intermittent failures, even after a connection becomes healthy again. With one click, you can get more information about a point in time, and fast access to any problematic sync in your workspace. [**Learn more >**](../cloud/managing-airbyte-cloud/review-connection-status)

<Arcade id="u3EEEqQoPRA4aoAAFFLO" title="Use the Connection Dashboard to diagnose unhealthy syncs" paddingBottom="calc(60% + 0px)" />

### Schema configuration updates in the connection Timeline

When someone makes a change to a connection's schema, Airbyte now logs an event in the connection's Timeline page. This data can help you understand why sync behaviors or record volumes suddenly changed. [**Learn more >**](../cloud/managing-airbyte-cloud/review-connection-timeline)

![A connection Timeline showing a different count of records after a schema change](assets/1-6-connection-timeline.png)

### Copy JSON from connectors

All connectors now have a **Copy JSON** button in the Airbyte UI. This button generates a JSON object matching the configuration of that connector. It's ready for use in Airbyte's API and Terraform provider. [**Learn more >**](../terraform-documentation#weakly-typed-json-configurations)

```json title="Airbyte source connector example"
{
  "name": "Airbyte",
  "workspaceId": "c0e5b294-2c71-475b-ae9c-6d70b36ff4f4",
  "definitionId": "284f6466-3004-4d83-a9b2-e4b36cbbbd41",
  "configuration": {
    "client_id": "******", // Replace this with your real client ID.
    "start_date": "2024-01-01T00:00:00Z",
    "client_secret": "******" // Replace this with your real client secret.
  }
}
```

### Connector Builder improvements

Airbyte's Connector Builder has new features to target more advanced and complex API sources: asynchronous endpoints, non-REST APIs, new response formats, and more.

#### Asynchronous streams

The Connector Builder UI now supports asynchronous streams, allowing you to handle scenarios where data extraction happens over multiple steps. Some APIs that handle large datasets or perform resource-intensive operations do not support synchronous requests. By setting up a stream as asynchronous, you can separate creating a request, polling for a response, and downloading the response into distinct steps. [**Learn more >**](../connector-development/connector-builder-ui/async-streams)

![Connector Builder UI showing an async stream with separate tabs for Creation, Polling, Download, and Schema](assets/1-6-asynchronous-streams.png)

#### GraphQL request body

You can write request bodies as free form GraphQL queries with built-in syntax validation.

![Connector Builder UI showing a GraphQL query in the request body](assets/1-6-graphql.png)

#### Handle CSV, gzip, and ZIP response formats

Airbyte has two new ways to handle API responses in the Connector Builder.

- **CSV decoding**: Make requests to sources that respond in CSV format and set expected delimiter and encoding options.

- **Nested decoding**. Make requests to sources that respond with compressed `gzip` or `zip` files, then set a nested decoding option to handle the unzipped contents within.

[**Learn More >**](../connector-development/connector-builder-ui/record-processing/#response-decoding)

![A stream that returns a zip file with a CSV inside](assets/1-6-decoders.png)

### Create custom connectors from YAML or Docker images using the API and Terraform

Airbyte's public APIs and Terraform provider have new endpoints and resources you can use to create and update custom connectors using a Connector Builder YAML manifest or Docker image. The following new endpoints are available.

For YAML source definitions:

- `GET` - /workspaces/`{workspaceId}`/definitions/declarative_sources/ - List YAML source definitions
- `POST` - /workspaces/`{workspaceId}`/definitions/declarative_sources/ - Create YAML source definitions
- `GET/` - /workspaces/`{workspaceId}`/definitions/declarative_sources/`{definitionId}` - Get a specific YAML source definition
- `PUT` - /workspaces/`{workspaceId}`/definitions/declarative_sources/`{definitionId}` - Update a specific YAML source definition
- `DELETE` - /workspaces/`{workspaceId}`/definitions/declarative_sources/`{definitionId}` - Delete a specific YAML source definition

For Docker source definitions:

- `GET` - /workspaces/`{workspaceId}`/definitions/sources/ - List source definitions
- `POST` - /workspaces/`{workspaceId}`/definitions/sources/ - Create source definitions
- `GET` - /workspaces/`{workspaceId}`/definitions/sources/`{definitionId}` - Get a specific source definition
- `PUT` - /workspaces/`{workspaceId}`/definitions/sources/`{definitionId}` - Update a specific source definition
- `DELETE` - /workspaces/`{workspaceId}`/definitions/sources/`{definitionId}` - Delete a specific source definition

For destination definitions:

- `GET` /workspaces/`{workspaceId}`/definitions/destinations - List destination definitions
- `POST` /workspaces/`{workspaceId}`/definitions/destinations - Create destination definitions
- `GET` /workspaces/`{workspaceId}`/definitions/destinations/`{definitionId}` - Get a specific destination definition
- `PUT` /workspaces/`{workspaceId}`/definitions/destinations/`{definitionId}` - Update a specific destination definition
- `DELETE` /workspaces/`{workspaceId}`/definitions/destinations/`{definitionId}` - Delete a specific destination definition

You can't use these endpoints to modify Airbyte's public connector definitions. If you're using the Cloud version of Airbyte, you can only create or modify custom connectors using a YAML manifest.

[**API reference docs >**](https://reference.airbyte.com/reference/getting-started#/)

[**Terraform reference docs >**](https://registry.terraform.io/providers/airbytehq/airbyte/latest/docs)

## 🚀 Self-Managed Enterprise changes

These changes bring new capabilities to Airbyte's Self-Managed Enterprise customers.

:::danger Breaking Change
Before upgrading from version 1.5.1 or earlier, you must upgrade your service account permissions. If you don't, Airbyte doesn't permit you to begin the upgrade. [Learn more](../enterprise-setup/upgrade-service-account.md).
:::

### Deploy Airbyte across multiple regions

Self-Managed Enterprise customers can now build data pipelines across multiple isolated regions (data planes), all governed from a single Airbyte deployment. For each Airbyte workspace, you can select the region where syncs run, ensuring pipelines spin up in specific physical locations. This enables you to meet compliance needs, run across different cloud vendors, and reduce cross-region egress fees. Region and data plane configuration is available via Airbyte's public API, and the Organization Settings page in the UI helps you easily identify the region associated with each workspace. [**Learn more >**](../enterprise-setup/multi-region)

![Stylized diagram showing a control plane with multiple data planes in different geographical regions](assets/1-6-data-planes.png)

## Unique stream prefixes or namespaces are now mandatory

Airbyte now requires that stream identifiers be unique across Airbyte connections that share a destination. You can no longer set multiple connections to sync to the same destination stream.

A common scenario looks like this: you have multiple accounts for the same source API and want to sync all this data to a single table in your destination. Although convenient, doing this carried a risk of data loss as multiple connections clashed with each other while writing to the same table.

After careful consideration, Airbyte has stopped supporting this. You must use a unique prefix for each stream or a unique namespace in each connection. Then, you can combine your tables downstream of Airbyte. [Learn more >](../using-airbyte/configuring-schema#stream-uniqueness)
