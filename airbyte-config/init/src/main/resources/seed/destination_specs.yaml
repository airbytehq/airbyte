# This file is generated by io.airbyte.config.specs.SeedConnectorSpecGenerator.
# Do NOT edit this file directly. See generator class for more details.
---
- dockerImage: "airbyte/destination-azure-blob-storage:0.1.3"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/azureblobstorage"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "AzureBlobStorage Destination Spec"
      type: "object"
      required:
      - "azure_blob_storage_account_name"
      - "azure_blob_storage_account_key"
      - "format"
      additionalProperties: false
      properties:
        azure_blob_storage_endpoint_domain_name:
          title: "Endpoint Domain Name"
          type: "string"
          default: "blob.core.windows.net"
          description: "This is Azure Blob Storage endpoint domain name. Leave default\
            \ value (or leave it empty if run container from command line) to use\
            \ Microsoft native from example."
          examples:
          - "blob.core.windows.net"
        azure_blob_storage_container_name:
          title: "Azure blob storage container (Bucket) Name"
          type: "string"
          description: "The name of the Azure blob storage container. If not exists\
            \ - will be created automatically. May be empty, then will be created\
            \ automatically airbytecontainer+timestamp"
          examples:
          - "airbytetescontainername"
        azure_blob_storage_account_name:
          title: "Azure Blob Storage account name"
          type: "string"
          description: "The account's name of the Azure Blob Storage."
          examples:
          - "airbyte5storage"
        azure_blob_storage_account_key:
          title: "Azure Blob Storage account key"
          description: "The Azure blob storage account key."
          airbyte_secret: true
          type: "string"
          examples:
          - "Z8ZkZpteggFx394vm+PJHnGTvdRncaYS+JhLKdj789YNmD+iyGTnG+PV+POiuYNhBg/ACS+LKjd%4FG3FHGN12Nd=="
        azure_blob_storage_output_buffer_size:
          title: "Azure Blob Storage output buffer size (Megabytes)"
          type: "integer"
          description: "The amount of megabytes to buffer for the output stream to\
            \ Azure. This will impact memory footprint on workers, but may need adjustment\
            \ for performance and appropriate block size in Azure."
          minimum: 1
          maximum: 2047
          default: 5
          examples:
          - 5
        format:
          title: "Output Format"
          type: "object"
          description: "Output data format"
          oneOf:
          - title: "CSV: Comma-Separated Values"
            required:
            - "format_type"
            - "flattening"
            properties:
              format_type:
                type: "string"
                const: "CSV"
              flattening:
                type: "string"
                title: "Normalization (Flattening)"
                description: "Whether the input json data should be normalized (flattened)\
                  \ in the output CSV. Please refer to docs for details."
                default: "No flattening"
                enum:
                - "No flattening"
                - "Root level flattening"
          - title: "JSON Lines: newline-delimited JSON"
            required:
            - "format_type"
            properties:
              format_type:
                type: "string"
                const: "JSONL"
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-amazon-sqs:0.1.0"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/amazon-sqs"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Destination Amazon Sqs"
      type: "object"
      required:
      - "queue_url"
      - "region"
      additionalProperties: false
      properties:
        queue_url:
          title: "Queue URL"
          description: "URL of the SQS Queue"
          type: "string"
          examples:
          - "https://sqs.eu-west-1.amazonaws.com/1234567890/my-example-queue"
          order: 0
        region:
          title: "AWS Region"
          description: "AWS Region of the SQS Queue"
          type: "string"
          enum:
          - "us-east-1"
          - "us-east-2"
          - "us-west-1"
          - "us-west-2"
          - "af-south-1"
          - "ap-east-1"
          - "ap-south-1"
          - "ap-northeast-1"
          - "ap-northeast-2"
          - "ap-northeast-3"
          - "ap-southeast-1"
          - "ap-southeast-2"
          - "ca-central-1"
          - "cn-north-1"
          - "cn-northwest-1"
          - "eu-central-1"
          - "eu-north-1"
          - "eu-south-1"
          - "eu-west-1"
          - "eu-west-2"
          - "eu-west-3"
          - "sa-east-1"
          - "me-south-1"
          - "us-gov-east-1"
          - "us-gov-west-1"
          order: 1
        message_delay:
          title: "Message Delay"
          description: "Modify the Message Delay of the individual message from the\
            \ Queue's default (seconds)."
          type: "integer"
          examples:
          - "15"
          order: 2
        access_key:
          title: "AWS IAM Access Key ID"
          description: "The Access Key ID of the AWS IAM Role to use for sending \
            \ messages"
          type: "string"
          examples:
          - "xxxxxHRNxxx3TBxxxxxx"
          order: 3
          airbyte_secret: true
        secret_key:
          title: "AWS IAM Secret Key"
          description: "The Secret Key of the AWS IAM Role to use for sending messages"
          type: "string"
          examples:
          - "hu+qE5exxxxT6o/ZrKsxxxxxxBhxxXLexxxxxVKz"
          order: 4
          airbyte_secret: true
        message_body_key:
          title: "Message Body Key"
          description: "Use this property to extract the contents of the named key\
            \ in the input record to use as the SQS message body. If not set, the\
            \ entire content of the input record data is used as the message body."
          type: "string"
          examples:
          - "myDataPath"
          order: 5
        message_group_id:
          title: "Message Group Id"
          description: "The tag that specifies that a message belongs to a specific\
            \ message group. This parameter applies only to, and is REQUIRED by, FIFO\
            \ queues."
          type: "string"
          examples:
          - "my-fifo-group"
          order: 6
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "append"
- dockerImage: "airbyte/destination-aws-datalake:0.1.0"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/aws-datalake"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "AWS Datalake Destination Spec"
      type: "object"
      required:
      - "credentials"
      - "region"
      - "bucket_name"
      - "bucket_prefix"
      additionalProperties: false
      properties:
        aws_account_id:
          type: "string"
          title: "AWS Account Id"
          description: "target aws account id"
          examples:
          - "111111111111"
        region:
          title: "AWS Region"
          type: "string"
          description: "Region name"
          airbyte_secret: false
        credentials:
          title: "Authentication mode"
          description: "Choose How to Authenticate to AWS."
          type: "object"
          oneOf:
          - type: "object"
            title: "IAM Role"
            required:
            - "role_arn"
            - "credentials_title"
            properties:
              credentials_title:
                type: "string"
                title: "Credentials Title"
                description: "Name of the credentials"
                const: "IAM Role"
                enum:
                - "IAM Role"
                default: "IAM Role"
                order: 0
              role_arn:
                title: "Target Role Arn"
                type: "string"
                description: "Will assume this role to write data to s3"
                airbyte_secret: false
          - type: "object"
            title: "IAM User"
            required:
            - "credentials_title"
            - "aws_access_key_id"
            - "aws_secret_access_key_id"
            properties:
              credentials_title:
                type: "string"
                title: "Credentials Title"
                description: "Name of the credentials"
                const: "IAM User"
                enum:
                - "IAM User"
                default: "IAM User"
                order: 0
              aws_access_key_id:
                title: "Access Key Id"
                type: "string"
                description: "AWS User Access Key Id"
                airbyte_secret: true
              aws_secret_access_key:
                title: "Secret Access Key"
                type: "string"
                description: "Secret Access Key"
                airbyte_secret: true
        bucket_name:
          title: "S3 Bucket Name"
          type: "string"
          description: "Name of the bucket"
          airbyte_secret: false
        bucket_prefix:
          title: "Target S3 Bucket Prefix"
          type: "string"
          description: "S3 prefix"
          airbyte_secret: false
        lakeformation_database_name:
          title: "Lakeformation Database Name"
          type: "string"
          description: "Which database to use"
          airbyte_secret: false
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-bigquery:1.1.1"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/bigquery"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "BigQuery Destination Spec"
      type: "object"
      required:
      - "project_id"
      - "dataset_id"
      additionalProperties: true
      properties:
        big_query_client_buffer_size_mb:
          title: "Google BigQuery Client Chunk Size (Optional)"
          description: "Google BigQuery client's chunk (buffer) size (MIN=1, MAX =\
            \ 15) for each table. The size that will be written by a single RPC. Written\
            \ data will be buffered and only flushed upon reaching this size or closing\
            \ the channel. The default 15MB value is used if not set explicitly. Read\
            \ more <a href=\"https://googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.client.Client.html\"\
            >here</a>."
          type: "integer"
          minimum: 1
          maximum: 15
          default: 15
          examples:
          - "15"
        project_id:
          type: "string"
          description: "The GCP project ID for the project containing the target BigQuery\
            \ dataset. Read more <a href=\"https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects\"\
            >here</a>."
          title: "Project ID"
        dataset_id:
          type: "string"
          description: "The default BigQuery Dataset ID that tables are replicated\
            \ to if the source does not specify a namespace. Read more <a href=\"\
            https://cloud.google.com/bigquery/docs/datasets#create-dataset\">here</a>."
          title: "Default Dataset ID"
        dataset_location:
          type: "string"
          description: "The location of the dataset. Warning: Changes made after creation\
            \ will not be applied. The default \"US\" value is used if not set explicitly.\
            \ Read more <a href=\"https://cloud.google.com/bigquery/docs/locations\"\
            >here</a>."
          title: "Dataset Location (Optional)"
          default: "US"
          enum:
          - "US"
          - "EU"
          - "asia-east1"
          - "asia-east2"
          - "asia-northeast1"
          - "asia-northeast2"
          - "asia-northeast3"
          - "asia-south1"
          - "asia-south2"
          - "asia-southeast1"
          - "asia-southeast2"
          - "australia-southeast1"
          - "australia-southeast2"
          - "europe-central2"
          - "europe-north1"
          - "europe-west1"
          - "europe-west2"
          - "europe-west3"
          - "europe-west4"
          - "europe-west6"
          - "northamerica-northeast1"
          - "northamerica-northeast2"
          - "southamerica-east1"
          - "southamerica-west1"
          - "us-central1"
          - "us-east1"
          - "us-east4"
          - "us-west1"
          - "us-west2"
          - "us-west3"
          - "us-west4"
        credentials_json:
          type: "string"
          description: "The contents of the JSON service account key. Check out the\
            \ <a href=\"https://docs.airbyte.com/integrations/destinations/bigquery#service-account-key\"\
            >docs</a> if you need help generating this key. Default credentials will\
            \ be used if this field is left empty."
          title: "Service Account Key JSON (Optional)"
          airbyte_secret: true
        transformation_priority:
          type: "string"
          description: "Interactive run type means that the query is executed as soon\
            \ as possible, and these queries count towards concurrent rate limit and\
            \ daily limit. Read more about interactive run type <a href=\"https://cloud.google.com/bigquery/docs/running-queries#queries\"\
            >here</a>. Batch queries are queued and started as soon as idle resources\
            \ are available in the BigQuery shared resource pool, which usually occurs\
            \ within a few minutes. Batch queries don’t count towards your concurrent\
            \ rate limit. Read more about batch queries <a href=\"https://cloud.google.com/bigquery/docs/running-queries#batch\"\
            >here</a>. The default \"interactive\" value is used if not set explicitly."
          title: "Transformation Query Run Type (Optional)"
          default: "interactive"
          enum:
          - "interactive"
          - "batch"
        loading_method:
          type: "object"
          title: "Loading Method"
          description: "Loading method used to send select the way data will be uploaded\
            \ to BigQuery. <br/><b>Standard Inserts</b> - Direct uploading using SQL\
            \ INSERT statements. This method is extremely inefficient and provided\
            \ only for quick testing. In almost all cases, you should use staging.\
            \ <br/><b>GCS Staging</b> - Writes large batches of records to a file,\
            \ uploads the file to GCS, then uses <b>COPY INTO table</b> to upload\
            \ the file. Recommended for most workloads for better speed and scalability.\
            \ Read more about GCS Staging <a href=\"https://docs.airbyte.com/integrations/destinations/bigquery#gcs-staging\"\
            >here</a>."
          oneOf:
          - title: "Standard Inserts"
            additionalProperties: false
            required:
            - "method"
            properties:
              method:
                type: "string"
                const: "Standard"
          - title: "GCS Staging"
            additionalProperties: false
            required:
            - "method"
            - "gcs_bucket_name"
            - "gcs_bucket_path"
            - "credential"
            properties:
              method:
                type: "string"
                const: "GCS Staging"
              gcs_bucket_name:
                title: "GCS Bucket Name"
                type: "string"
                description: "The name of the GCS bucket. Read more <a href=\"https://cloud.google.com/storage/docs/naming-buckets\"\
                  >here</a>."
                examples:
                - "airbyte_sync"
              gcs_bucket_path:
                title: "GCS Bucket Path"
                description: "Directory under the GCS bucket where data will be written."
                type: "string"
                examples:
                - "data_sync/test"
              part_size_mb:
                title: "Block Size (MB) for GCS Multipart Upload (Optional)"
                description: "This is the size of a \"Part\" being buffered in memory.\
                  \ It limits the memory usage when writing. Larger values will allow\
                  \ to upload a bigger files and improve the speed, but consumes more\
                  \ memory. Allowed values: min=5MB, max=525MB Default: 5MB."
                type: "integer"
                default: 5
                minimum: 5
                maximum: 525
                examples:
                - 5
              keep_files_in_gcs-bucket:
                type: "string"
                description: "This upload method is supposed to temporary store records\
                  \ in GCS bucket. What do you want to do with data in GCS bucket\
                  \ when migration has finished? The default \"Delete all tmp files\
                  \ from GCS\" value is used if not set explicitly."
                title: "GCS Tmp Files Afterward Processing (Optional)"
                default: "Delete all tmp files from GCS"
                enum:
                - "Delete all tmp files from GCS"
                - "Keep all tmp files in GCS"
              credential:
                title: "Credential"
                description: "An HMAC key is a type of credential and can be associated\
                  \ with a service account or a user account in Cloud Storage. Read\
                  \ more <a href=\"https://cloud.google.com/storage/docs/authentication/hmackeys\"\
                  >here</a>."
                type: "object"
                oneOf:
                - title: "HMAC key"
                  required:
                  - "credential_type"
                  - "hmac_key_access_id"
                  - "hmac_key_secret"
                  properties:
                    credential_type:
                      type: "string"
                      const: "HMAC_KEY"
                    hmac_key_access_id:
                      type: "string"
                      description: "HMAC key access ID. When linked to a service account,\
                        \ this ID is 61 characters long; when linked to a user account,\
                        \ it is 24 characters long."
                      title: "HMAC Key Access ID"
                      airbyte_secret: true
                      examples:
                      - "1234567890abcdefghij1234"
                    hmac_key_secret:
                      type: "string"
                      description: "The corresponding secret for the access ID. It\
                        \ is a 40-character base-64 encoded string."
                      title: "HMAC Key Secret"
                      airbyte_secret: true
                      examples:
                      - "1234567890abcdefghij1234567890ABCDEFGHIJ"
    supportsIncremental: true
    supportsNormalization: true
    supportsDBT: true
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
    - "append_dedup"
- dockerImage: "airbyte/destination-bigquery-denormalized:0.3.1"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/bigquery"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "BigQuery Denormalized Typed Struct Destination Spec"
      type: "object"
      required:
      - "project_id"
      - "dataset_id"
      additionalProperties: true
      properties:
        big_query_client_buffer_size_mb:
          title: "Google BigQuery Client Chunk Size (Optional)"
          description: "Google BigQuery client's chunk (buffer) size (MIN=1, MAX =\
            \ 15) for each table. The size that will be written by a single RPC. Written\
            \ data will be buffered and only flushed upon reaching this size or closing\
            \ the channel. The default 15MB value is used if not set explicitly. Read\
            \ more <a href=\"https://googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.client.Client.html\"\
            >here</a>."
          type: "integer"
          minimum: 1
          maximum: 15
          default: 15
          examples:
          - "15"
        project_id:
          type: "string"
          description: "The GCP project ID for the project containing the target BigQuery\
            \ dataset. Read more <a href=\"https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects\"\
            >here</a>."
          title: "Project ID"
        dataset_id:
          type: "string"
          description: "The default BigQuery Dataset ID that tables are replicated\
            \ to if the source does not specify a namespace. Read more <a href=\"\
            https://cloud.google.com/bigquery/docs/datasets#create-dataset\">here</a>."
          title: "Default Dataset ID"
        dataset_location:
          type: "string"
          description: "The location of the dataset. Warning: Changes made after creation\
            \ will not be applied. The default \"US\" value is used if not set explicitly.\
            \ Read more <a href=\"https://cloud.google.com/bigquery/docs/locations\"\
            >here</a>."
          title: "Dataset Location (Optional)"
          default: "US"
          enum:
          - "US"
          - "EU"
          - "asia-east1"
          - "asia-east2"
          - "asia-northeast1"
          - "asia-northeast2"
          - "asia-northeast3"
          - "asia-south1"
          - "asia-south2"
          - "asia-southeast1"
          - "asia-southeast2"
          - "australia-southeast1"
          - "australia-southeast2"
          - "europe-central2"
          - "europe-north1"
          - "europe-west1"
          - "europe-west2"
          - "europe-west3"
          - "europe-west4"
          - "europe-west6"
          - "northamerica-northeast1"
          - "northamerica-northeast2"
          - "southamerica-east1"
          - "southamerica-west1"
          - "us-central1"
          - "us-east1"
          - "us-east4"
          - "us-west1"
          - "us-west2"
          - "us-west3"
          - "us-west4"
        credentials_json:
          type: "string"
          description: "The contents of the JSON service account key. Check out the\
            \ <a href=\"https://docs.airbyte.com/integrations/destinations/bigquery#service-account-key\"\
            >docs</a> if you need help generating this key. Default credentials will\
            \ be used if this field is left empty."
          title: "Service Account Key JSON (Optional)"
          airbyte_secret: true
        loading_method:
          type: "object"
          title: "Loading Method *"
          description: "Loading method used to send select the way data will be uploaded\
            \ to BigQuery. <br/><b>Standard Inserts</b> - Direct uploading using SQL\
            \ INSERT statements. This method is extremely inefficient and provided\
            \ only for quick testing. In almost all cases, you should use staging.\
            \ <br/><b>GCS Staging</b> - Writes large batches of records to a file,\
            \ uploads the file to GCS, then uses <b>COPY INTO table</b> to upload\
            \ the file. Recommended for most workloads for better speed and scalability.\
            \ Read more about GCS Staging <a href=\"https://docs.airbyte.com/integrations/destinations/bigquery#gcs-staging\"\
            >here</a>."
          oneOf:
          - title: "Standard Inserts"
            additionalProperties: false
            required:
            - "method"
            properties:
              method:
                type: "string"
                const: "Standard"
          - title: "GCS Staging"
            additionalProperties: false
            required:
            - "method"
            - "gcs_bucket_name"
            - "gcs_bucket_path"
            - "credential"
            properties:
              method:
                type: "string"
                const: "GCS Staging"
              gcs_bucket_name:
                title: "GCS Bucket Name"
                type: "string"
                description: "The name of the GCS bucket. Read more <a href=\"https://cloud.google.com/storage/docs/naming-buckets\"\
                  >here</a>."
                examples:
                - "airbyte_sync"
              gcs_bucket_path:
                title: "GCS Bucket Path"
                description: "Directory under the GCS bucket where data will be written."
                type: "string"
                examples:
                - "data_sync/test"
              part_size_mb:
                title: "Block Size (MB) for GCS Multipart Upload (Optional)"
                description: "This is the size of a \"Part\" being buffered in memory.\
                  \ It limits the memory usage when writing. Larger values will allow\
                  \ to upload a bigger files and improve the speed, but consumes more\
                  \ memory. Allowed values: min=5MB, max=525MB Default: 5MB."
                type: "integer"
                default: 5
                minimum: 5
                maximum: 525
                examples:
                - 5
              keep_files_in_gcs-bucket:
                type: "string"
                description: "This upload method is supposed to temporary store records\
                  \ in GCS bucket. What do you want to do with data in GCS bucket\
                  \ when migration has finished? The default \"Delete all tmp files\
                  \ from GCS\" value is used if not set explicitly."
                title: "GCS Tmp Files Afterward Processing (Optional)"
                default: "Delete all tmp files from GCS"
                enum:
                - "Delete all tmp files from GCS"
                - "Keep all tmp files in GCS"
              credential:
                title: "Credential"
                description: "An HMAC key is a type of credential and can be associated\
                  \ with a service account or a user account in Cloud Storage. Read\
                  \ more <a href=\"https://cloud.google.com/storage/docs/authentication/hmackeys\"\
                  >here</a>."
                type: "object"
                oneOf:
                - title: "HMAC key"
                  required:
                  - "credential_type"
                  - "hmac_key_access_id"
                  - "hmac_key_secret"
                  properties:
                    credential_type:
                      type: "string"
                      const: "HMAC_KEY"
                    hmac_key_access_id:
                      type: "string"
                      description: "HMAC key access ID. When linked to a service account,\
                        \ this ID is 61 characters long; when linked to a user account,\
                        \ it is 24 characters long."
                      title: "HMAC Key Access ID"
                      airbyte_secret: true
                      examples:
                      - "1234567890abcdefghij1234"
                    hmac_key_secret:
                      type: "string"
                      description: "The corresponding secret for the access ID. It\
                        \ is a 40-character base-64 encoded string."
                      title: "HMAC Key Secret"
                      airbyte_secret: true
                      examples:
                      - "1234567890abcdefghij1234567890ABCDEFGHIJ"
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: true
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-cassandra:0.1.1"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/cassandra"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Cassandra Destination Spec"
      type: "object"
      required:
      - "keyspace"
      - "username"
      - "password"
      - "address"
      - "port"
      additionalProperties: true
      properties:
        keyspace:
          title: "Keyspace"
          description: "Default Cassandra keyspace to create data in."
          type: "string"
          order: 0
        username:
          title: "Username"
          description: "Username to use to access Cassandra."
          type: "string"
          order: 1
        password:
          title: "Password"
          description: "Password associated with Cassandra."
          type: "string"
          airbyte_secret: true
          order: 2
        address:
          title: "Address"
          description: "Address to connect to."
          type: "string"
          examples:
          - "localhost,127.0.0.1"
          order: 3
        port:
          title: "Port"
          description: "Port of Cassandra."
          type: "integer"
          minimum: 0
          maximum: 65536
          default: 9042
          order: 4
        datacenter:
          title: "Datacenter"
          description: "Datacenter of the cassandra cluster."
          type: "string"
          default: "datacenter1"
          order: 5
        replication:
          title: "Replication factor"
          type: "integer"
          description: "Indicates to how many nodes the data should be replicated\
            \ to."
          default: 1
          order: 6
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-keen:0.2.2"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/keen"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Keen Spec"
      type: "object"
      required:
      - "project_id"
      - "api_key"
      additionalProperties: false
      properties:
        project_id:
          description: "To get Keen Project ID, navigate to the Access tab from the\
            \ left-hand, side panel and check the Project Details section."
          title: "Project ID"
          type: "string"
          examples:
          - "58b4acc22ba938934e888322e"
        api_key:
          title: "API Key"
          description: "To get Keen Master API Key, navigate to the Access tab from\
            \ the left-hand, side panel and check the Project Details section."
          type: "string"
          examples:
          - "ABCDEFGHIJKLMNOPRSTUWXYZ"
          airbyte_secret: true
        infer_timestamp:
          title: "Infer Timestamp"
          description: "Allow connector to guess keen.timestamp value based on the\
            \ streamed data."
          type: "boolean"
          default: true
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-clickhouse:0.1.4"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/clickhouse"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "ClickHouse Destination Spec"
      type: "object"
      required:
      - "host"
      - "port"
      - "database"
      - "username"
      additionalProperties: true
      properties:
        host:
          title: "Host"
          description: "Hostname of the database."
          type: "string"
          order: 0
        port:
          title: "Port"
          description: "JDBC port (not the native port) of the database."
          type: "integer"
          minimum: 0
          maximum: 65536
          default: 8123
          examples:
          - "8123"
          order: 1
        tcp-port:
          title: "Native Port"
          description: "Native port (not the JDBC) of the database."
          type: "integer"
          minimum: 0
          maximum: 65536
          default: 9000
          examples:
          - "9000"
          order: 2
        database:
          title: "DB Name"
          description: "Name of the database."
          type: "string"
          order: 3
        username:
          title: "User"
          description: "Username to use to access the database."
          type: "string"
          order: 4
        password:
          title: "Password"
          description: "Password associated with the username."
          type: "string"
          airbyte_secret: true
          order: 5
        ssl:
          title: "SSL Connection"
          description: "Encrypt data using SSL."
          type: "boolean"
          default: false
          order: 6
        tunnel_method:
          type: "object"
          title: "SSH Tunnel Method"
          description: "Whether to initiate an SSH tunnel before connecting to the\
            \ database, and if so, which kind of authentication to use."
          oneOf:
          - title: "No Tunnel"
            required:
            - "tunnel_method"
            properties:
              tunnel_method:
                description: "No ssh tunnel needed to connect to database"
                type: "string"
                const: "NO_TUNNEL"
                order: 0
          - title: "SSH Key Authentication"
            required:
            - "tunnel_method"
            - "tunnel_host"
            - "tunnel_port"
            - "tunnel_user"
            - "ssh_key"
            properties:
              tunnel_method:
                description: "Connect through a jump server tunnel host using username\
                  \ and ssh key"
                type: "string"
                const: "SSH_KEY_AUTH"
                order: 0
              tunnel_host:
                title: "SSH Tunnel Jump Server Host"
                description: "Hostname of the jump server host that allows inbound\
                  \ ssh tunnel."
                type: "string"
                order: 1
              tunnel_port:
                title: "SSH Connection Port"
                description: "Port on the proxy/jump server that accepts inbound ssh\
                  \ connections."
                type: "integer"
                minimum: 0
                maximum: 65536
                default: 22
                examples:
                - "22"
                order: 2
              tunnel_user:
                title: "SSH Login Username"
                description: "OS-level username for logging into the jump server host."
                type: "string"
                order: 3
              ssh_key:
                title: "SSH Private Key"
                description: "OS-level user account ssh key credentials in RSA PEM\
                  \ format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )"
                type: "string"
                airbyte_secret: true
                multiline: true
                order: 4
          - title: "Password Authentication"
            required:
            - "tunnel_method"
            - "tunnel_host"
            - "tunnel_port"
            - "tunnel_user"
            - "tunnel_user_password"
            properties:
              tunnel_method:
                description: "Connect through a jump server tunnel host using username\
                  \ and password authentication"
                type: "string"
                const: "SSH_PASSWORD_AUTH"
                order: 0
              tunnel_host:
                title: "SSH Tunnel Jump Server Host"
                description: "Hostname of the jump server host that allows inbound\
                  \ ssh tunnel."
                type: "string"
                order: 1
              tunnel_port:
                title: "SSH Connection Port"
                description: "Port on the proxy/jump server that accepts inbound ssh\
                  \ connections."
                type: "integer"
                minimum: 0
                maximum: 65536
                default: 22
                examples:
                - "22"
                order: 2
              tunnel_user:
                title: "SSH Login Username"
                description: "OS-level username for logging into the jump server host"
                type: "string"
                order: 3
              tunnel_user_password:
                title: "Password"
                description: "OS-level password for logging into the jump server host"
                type: "string"
                airbyte_secret: true
                order: 4
    supportsIncremental: true
    supportsNormalization: true
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
    - "append_dedup"
- dockerImage: "airbyte/destination-dynamodb:0.1.2"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/dynamodb"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "DynamoDB Destination Spec"
      type: "object"
      required:
      - "dynamodb_table_name"
      - "dynamodb_region"
      - "access_key_id"
      - "secret_access_key"
      additionalProperties: false
      properties:
        dynamodb_endpoint:
          title: "Endpoint"
          type: "string"
          default: ""
          description: "This is your DynamoDB endpoint url.(if you are working with\
            \ AWS DynamoDB, just leave empty)."
          examples:
          - "http://localhost:9000"
        dynamodb_table_name:
          title: "DynamoDB Table Name"
          type: "string"
          description: "The name of the DynamoDB table."
          examples:
          - "airbyte_sync"
        dynamodb_region:
          title: "DynamoDB Region"
          type: "string"
          default: ""
          description: "The region of the DynamoDB."
          enum:
          - ""
          - "us-east-1"
          - "us-east-2"
          - "us-west-1"
          - "us-west-2"
          - "af-south-1"
          - "ap-east-1"
          - "ap-south-1"
          - "ap-northeast-1"
          - "ap-northeast-2"
          - "ap-northeast-3"
          - "ap-southeast-1"
          - "ap-southeast-2"
          - "ca-central-1"
          - "cn-north-1"
          - "cn-northwest-1"
          - "eu-central-1"
          - "eu-north-1"
          - "eu-south-1"
          - "eu-west-1"
          - "eu-west-2"
          - "eu-west-3"
          - "sa-east-1"
          - "me-south-1"
          - "us-gov-east-1"
          - "us-gov-west-1"
        access_key_id:
          type: "string"
          description: "The access key id to access the DynamoDB. Airbyte requires\
            \ Read and Write permissions to the DynamoDB."
          title: "DynamoDB Key Id"
          airbyte_secret: true
          examples:
          - "A012345678910EXAMPLE"
        secret_access_key:
          type: "string"
          description: "The corresponding secret to the access key id."
          title: "DynamoDB Access Key"
          airbyte_secret: true
          examples:
          - "a012345678910ABCDEFGH/AbCdEfGhEXAMPLEKEY"
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-e2e-test:0.2.2"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/e2e-test"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "E2E Test Destination Spec"
      type: "object"
      oneOf:
      - title: "Logging"
        required:
        - "type"
        - "logging_config"
        properties:
          type:
            type: "string"
            const: "LOGGING"
            default: "LOGGING"
          logging_config:
            title: "Logging Configuration"
            type: "object"
            description: "Configurate how the messages are logged."
            oneOf:
            - title: "First N Entries"
              description: "Log first N entries per stream."
              type: "object"
              required:
              - "logging_type"
              - "max_entry_count"
              properties:
                logging_type:
                  type: "string"
                  enum:
                  - "FirstN"
                  default: "FirstN"
                max_entry_count:
                  title: "N"
                  description: "Number of entries to log. This destination is for\
                    \ testing only. So it won't make sense to log infinitely. The\
                    \ maximum is 1,000 entries."
                  type: "number"
                  default: 100
                  examples:
                  - 100
                  minimum: 1
                  maximum: 1000
            - title: "Every N-th Entry"
              description: "For each stream, log every N-th entry with a maximum cap."
              type: "object"
              required:
              - "logging_type"
              - "nth_entry_to_log"
              - "max_entry_count"
              properties:
                logging_type:
                  type: "string"
                  enum:
                  - "EveryNth"
                  default: "EveryNth"
                nth_entry_to_log:
                  title: "N"
                  description: "The N-th entry to log for each stream. N starts from\
                    \ 1. For example, when N = 1, every entry is logged; when N =\
                    \ 2, every other entry is logged; when N = 3, one out of three\
                    \ entries is logged."
                  type: "number"
                  example:
                  - 3
                  minimum: 1
                  maximum: 1000
                max_entry_count:
                  title: "Max Log Entries"
                  description: "Max number of entries to log. This destination is\
                    \ for testing only. So it won't make sense to log infinitely.\
                    \ The maximum is 1,000 entries."
                  type: "number"
                  default: 100
                  examples:
                  - 100
                  minimum: 1
                  maximum: 1000
            - title: "Random Sampling"
              description: "For each stream, randomly log a percentage of the entries\
                \ with a maximum cap."
              type: "object"
              required:
              - "logging_type"
              - "sampling_ratio"
              - "max_entry_count"
              properties:
                logging_type:
                  type: "string"
                  enum:
                  - "RandomSampling"
                  default: "RandomSampling"
                sampling_ratio:
                  title: "Sampling Ratio"
                  description: "A positive floating number smaller than 1."
                  type: "number"
                  default: 0.001
                  examples:
                  - 0.001
                  minimum: 0
                  maximum: 1
                seed:
                  title: "Random Number Generator Seed"
                  description: "When the seed is unspecified, the current time millis\
                    \ will be used as the seed."
                  type: "number"
                  examples:
                  - 1900
                max_entry_count:
                  title: "Max Log Entries"
                  description: "Max number of entries to log. This destination is\
                    \ for testing only. So it won't make sense to log infinitely.\
                    \ The maximum is 1,000 entries."
                  type: "number"
                  default: 100
                  examples:
                  - 100
                  minimum: 1
                  maximum: 1000
      - title: "Silent"
        required:
        - "type"
        properties:
          type:
            type: "string"
            const: "SILENT"
            default: "SILENT"
      - title: "Throttled"
        required:
        - "type"
        - "millis_per_record"
        properties:
          type:
            type: "string"
            const: "THROTTLED"
            default: "THROTTLED"
          millis_per_record:
            description: "Number of milli-second to pause in between records."
            type: "integer"
      - title: "Failing"
        required:
        - "type"
        - "num_messages"
        properties:
          type:
            type: "string"
            const: "FAILING"
            default: "FAILING"
          num_messages:
            description: "Number of messages after which to fail."
            type: "integer"
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-elasticsearch:0.1.1"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/elasticsearch"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Elasticsearch Connection Configuration"
      type: "object"
      required:
      - "endpoint"
      additionalProperties: false
      properties:
        endpoint:
          title: "Server Endpoint"
          type: "string"
          description: "The full url of the Elasticsearch server"
        upsert:
          type: "boolean"
          title: "Upsert Records"
          description: "If a primary key identifier is defined in the source, an upsert\
            \ will be performed using the primary key value as the elasticsearch doc\
            \ id. Does not support composite primary keys."
          default: true
        authenticationMethod:
          title: "Authentication Method"
          type: "object"
          description: "The type of authentication to be used"
          oneOf:
          - title: "None"
            additionalProperties: false
            description: "No authentication will be used"
            required:
            - "method"
            properties:
              method:
                type: "string"
                const: "none"
          - title: "Api Key/Secret"
            additionalProperties: false
            description: "Use a api key and secret combination to authenticate"
            required:
            - "method"
            - "apiKeyId"
            - "apiKeySecret"
            properties:
              method:
                type: "string"
                const: "secret"
              apiKeyId:
                title: "API Key ID"
                description: "The Key ID to used when accessing an enterprise Elasticsearch\
                  \ instance."
                type: "string"
              apiKeySecret:
                title: "API Key Secret"
                description: "The secret associated with the API Key ID."
                type: "string"
                airbyte_secret: true
          - title: "Username/Password"
            additionalProperties: false
            description: "Basic auth header with a username and password"
            required:
            - "method"
            - "username"
            - "password"
            properties:
              method:
                type: "string"
                const: "basic"
              username:
                title: "Username"
                description: "Basic auth username to access a secure Elasticsearch\
                  \ server"
                type: "string"
              password:
                title: "Password"
                description: "Basic auth password to access a secure Elasticsearch\
                  \ server"
                type: "string"
                airbyte_secret: true
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
    supportsNamespaces: true
- dockerImage: "airbyte/destination-gcs:0.2.4"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/gcs"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "GCS Destination Spec"
      type: "object"
      required:
      - "gcs_bucket_name"
      - "gcs_bucket_path"
      - "credential"
      - "format"
      additionalProperties: false
      properties:
        gcs_bucket_name:
          title: "GCS Bucket Name"
          order: 1
          type: "string"
          description: "You can find the bucket name in the App Engine Admin console\
            \ Application Settings page, under the label Google Cloud Storage Bucket.\
            \ Read more <a href=\"https://cloud.google.com/storage/docs/naming-buckets\"\
            >here</a>."
          examples:
          - "airbyte_sync"
        gcs_bucket_path:
          title: "GCS Bucket Path"
          description: "GCS Bucket Path string Subdirectory under the above bucket\
            \ to sync the data into."
          order: 2
          type: "string"
          examples:
          - "data_sync/test"
        gcs_bucket_region:
          title: "GCS Bucket Region (Optional)"
          type: "string"
          order: 3
          default: "us"
          description: "Select a Region of the GCS Bucket. Read more <a href=\"https://cloud.google.com/storage/docs/locations\"\
            >here</a>."
          enum:
          - "northamerica-northeast1"
          - "northamerica-northeast2"
          - "us-central1"
          - "us-east1"
          - "us-east4"
          - "us-west1"
          - "us-west2"
          - "us-west3"
          - "us-west4"
          - "southamerica-east1"
          - "southamerica-west1"
          - "europe-central2"
          - "europe-north1"
          - "europe-west1"
          - "europe-west2"
          - "europe-west3"
          - "europe-west4"
          - "europe-west6"
          - "asia-east1"
          - "asia-east2"
          - "asia-northeast1"
          - "asia-northeast2"
          - "asia-northeast3"
          - "asia-south1"
          - "asia-south2"
          - "asia-southeast1"
          - "asia-southeast2"
          - "australia-southeast1"
          - "australia-southeast2"
          - "asia"
          - "eu"
          - "us"
          - "asia1"
          - "eur4"
          - "nam4"
        credential:
          title: "Authentication"
          description: "An HMAC key is a type of credential and can be associated\
            \ with a service account or a user account in Cloud Storage. Read more\
            \ <a href=\"https://cloud.google.com/storage/docs/authentication/hmackeys\"\
            >here</a>."
          type: "object"
          order: 0
          oneOf:
          - title: "HMAC Key"
            required:
            - "credential_type"
            - "hmac_key_access_id"
            - "hmac_key_secret"
            properties:
              credential_type:
                type: "string"
                enum:
                - "HMAC_KEY"
                default: "HMAC_KEY"
              hmac_key_access_id:
                type: "string"
                description: "When linked to a service account, this ID is 61 characters\
                  \ long; when linked to a user account, it is 24 characters long.\
                  \ Read more <a href=\"https://cloud.google.com/storage/docs/authentication/hmackeys#overview\"\
                  >here</a>."
                title: "Access ID"
                airbyte_secret: true
                order: 0
                examples:
                - "1234567890abcdefghij1234"
              hmac_key_secret:
                type: "string"
                description: "The corresponding secret for the access ID. It is a\
                  \ 40-character base-64 encoded string.  Read more <a href=\"https://cloud.google.com/storage/docs/authentication/hmackeys#secrets\"\
                  >here</a>."
                title: "Secret"
                airbyte_secret: true
                order: 1
                examples:
                - "1234567890abcdefghij1234567890ABCDEFGHIJ"
        format:
          title: "Output Format"
          type: "object"
          description: "Output data format. One of the following formats must be selected\
            \ - <a href=\"https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-avro#advantages_of_avro\"\
            >AVRO</a> format, <a href=\"https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet#parquet_schemas\"\
            >PARQUET</a> format, <a href=\"https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv#loading_csv_data_into_a_table\"\
            >CSV</a> format, or <a href=\"https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json#loading_json_data_into_a_new_table\"\
            >JSONL</a> format."
          order: 4
          oneOf:
          - title: "Avro: Apache Avro"
            required:
            - "format_type"
            - "compression_codec"
            properties:
              format_type:
                type: "string"
                enum:
                - "Avro"
                default: "Avro"
              compression_codec:
                title: "Compression Codec"
                description: "The compression algorithm used to compress data. Default\
                  \ to no compression."
                type: "object"
                oneOf:
                - title: "No Compression"
                  required:
                  - "codec"
                  properties:
                    codec:
                      type: "string"
                      enum:
                      - "no compression"
                      default: "no compression"
                - title: "Deflate"
                  required:
                  - "codec"
                  properties:
                    codec:
                      type: "string"
                      enum:
                      - "Deflate"
                      default: "Deflate"
                    compression_level:
                      title: "Deflate level (Optional)"
                      description: "0: no compression & fastest, 9: best compression\
                        \ & slowest."
                      type: "integer"
                      default: 0
                      minimum: 0
                      maximum: 9
                - title: "bzip2"
                  required:
                  - "codec"
                  properties:
                    codec:
                      type: "string"
                      enum:
                      - "bzip2"
                      default: "bzip2"
                - title: "xz"
                  required:
                  - "codec"
                  properties:
                    codec:
                      type: "string"
                      enum:
                      - "xz"
                      default: "xz"
                    compression_level:
                      title: "Compression Level (Optional)"
                      description: "The presets 0-3 are fast presets with medium compression.\
                        \ The presets 4-6 are fairly slow presets with high compression.\
                        \ The default preset is 6. The presets 7-9 are like the preset\
                        \ 6 but use bigger dictionaries and have higher compressor\
                        \ and decompressor memory requirements. Unless the uncompressed\
                        \ size of the file exceeds 8 MiB, 16 MiB, or 32 MiB, it is\
                        \ waste of memory to use the presets 7, 8, or 9, respectively.\
                        \ Read more <a href=\"https://commons.apache.org/proper/commons-compress/apidocs/org/apache/commons/compress/compressors/xz/XZCompressorOutputStream.html#XZCompressorOutputStream-java.io.OutputStream-int-\"\
                        >here</a> for details."
                      type: "integer"
                      default: 6
                      minimum: 0
                      maximum: 9
                - title: "zstandard"
                  required:
                  - "codec"
                  properties:
                    codec:
                      type: "string"
                      enum:
                      - "zstandard"
                      default: "zstandard"
                    compression_level:
                      title: "Compression Level (Optional)"
                      description: "Negative levels are 'fast' modes akin to lz4 or\
                        \ snappy, levels above 9 are generally for archival purposes,\
                        \ and levels above 18 use a lot of memory."
                      type: "integer"
                      default: 3
                      minimum: -5
                      maximum: 22
                    include_checksum:
                      title: "Include Checksum (Optional)"
                      description: "If true, include a checksum with each data block."
                      type: "boolean"
                      default: false
                - title: "snappy"
                  required:
                  - "codec"
                  properties:
                    codec:
                      type: "string"
                      enum:
                      - "snappy"
                      default: "snappy"
              part_size_mb:
                title: "Block Size (MB) for GCS multipart upload (Optional)"
                description: "This is the size of a \"Part\" being buffered in memory.\
                  \ It limits the memory usage when writing. Larger values will allow\
                  \ to upload a bigger files and improve the speed, but consumes9\
                  \ more memory. Allowed values: min=5MB, max=525MB Default: 5MB."
                type: "integer"
                default: 5
                examples:
                - 5
          - title: "CSV: Comma-Separated Values"
            required:
            - "format_type"
            properties:
              format_type:
                type: "string"
                enum:
                - "CSV"
                default: "CSV"
              flattening:
                type: "string"
                title: "Normalization (Optional)"
                description: "Whether the input JSON data should be normalized (flattened)\
                  \ in the output CSV. Please refer to docs for details."
                default: "No flattening"
                enum:
                - "No flattening"
                - "Root level flattening"
              part_size_mb:
                title: "Block Size (MB) for GCS multipart upload (Optional)"
                description: "This is the size of a \"Part\" being buffered in memory.\
                  \ It limits the memory usage when writing. Larger values will allow\
                  \ to upload a bigger files and improve the speed, but consumes9\
                  \ more memory. Allowed values: min=5MB, max=525MB Default: 5MB."
                type: "integer"
                default: 5
                examples:
                - 5
              compression:
                title: "Compression"
                type: "object"
                description: "Whether the output files should be compressed. If compression\
                  \ is selected, the output filename will have an extra extension\
                  \ (GZIP: \".csv.gz\")."
                oneOf:
                - title: "No Compression"
                  requires:
                  - "compression_type"
                  properties:
                    compression_type:
                      type: "string"
                      enum:
                      - "No Compression"
                      default: "No Compression"
                - title: "GZIP"
                  requires:
                  - "compression_type"
                  properties:
                    compression_type:
                      type: "string"
                      enum:
                      - "GZIP"
                      default: "GZIP"
          - title: "JSON Lines: newline-delimited JSON"
            required:
            - "format_type"
            properties:
              format_type:
                type: "string"
                enum:
                - "JSONL"
                default: "JSONL"
              part_size_mb:
                title: "Block Size (MB) for GCS multipart upload (Optional)"
                description: "This is the size of a \"Part\" being buffered in memory.\
                  \ It limits the memory usage when writing. Larger values will allow\
                  \ to upload a bigger files and improve the speed, but consumes9\
                  \ more memory. Allowed values: min=5MB, max=525MB Default: 5MB."
                type: "integer"
                default: 5
                examples:
                - 5
              compression:
                title: "Compression"
                type: "object"
                description: "Whether the output files should be compressed. If compression\
                  \ is selected, the output filename will have an extra extension\
                  \ (GZIP: \".jsonl.gz\")."
                oneOf:
                - title: "No Compression"
                  requires: "compression_type"
                  properties:
                    compression_type:
                      type: "string"
                      enum:
                      - "No Compression"
                      default: "No Compression"
                - title: "GZIP"
                  requires: "compression_type"
                  properties:
                    compression_type:
                      type: "string"
                      enum:
                      - "GZIP"
                      default: "GZIP"
          - title: "Parquet: Columnar Storage"
            required:
            - "format_type"
            properties:
              format_type:
                type: "string"
                enum:
                - "Parquet"
                default: "Parquet"
              compression_codec:
                title: "Compression Codec (Optional)"
                description: "The compression algorithm used to compress data pages."
                type: "string"
                default: "UNCOMPRESSED"
                enum:
                - "UNCOMPRESSED"
                - "SNAPPY"
                - "GZIP"
                - "LZO"
                - "BROTLI"
                - "LZ4"
                - "ZSTD"
              block_size_mb:
                title: "Block Size (Row Group Size) (MB) (Optional)"
                description: "This is the size of a row group being buffered in memory.\
                  \ It limits the memory usage when writing. Larger values will improve\
                  \ the IO when reading, but consume more memory when writing. Default:\
                  \ 128 MB."
                type: "integer"
                default: 128
                examples:
                - 128
              max_padding_size_mb:
                title: "Max Padding Size (MB) (Optional)"
                description: "Maximum size allowed as padding to align row groups.\
                  \ This is also the minimum size of a row group. Default: 8 MB."
                type: "integer"
                default: 8
                examples:
                - 8
              page_size_kb:
                title: "Page Size (KB) (Optional)"
                description: "The page size is for compression. A block is composed\
                  \ of pages. A page is the smallest unit that must be read fully\
                  \ to access a single record. If this value is too small, the compression\
                  \ will deteriorate. Default: 1024 KB."
                type: "integer"
                default: 1024
                examples:
                - 1024
              dictionary_page_size_kb:
                title: "Dictionary Page Size (KB) (Optional)"
                description: "There is one dictionary page per column per row group\
                  \ when dictionary encoding is used. The dictionary page size works\
                  \ like the page size but for dictionary. Default: 1024 KB."
                type: "integer"
                default: 1024
                examples:
                - 1024
              dictionary_encoding:
                title: "Dictionary Encoding (Optional)"
                description: "Default: true."
                type: "boolean"
                default: true
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
    $schema: "http://json-schema.org/draft-07/schema#"
- dockerImage: "airbyte/destination-firestore:0.1.1"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/firestore"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Destination Google Firestore"
      type: "object"
      required:
      - "project_id"
      additionalProperties: false
      properties:
        project_id:
          type: "string"
          description: "The GCP project ID for the project containing the target BigQuery\
            \ dataset."
          title: "Project ID"
        credentials_json:
          type: "string"
          description: "The contents of the JSON service account key. Check out the\
            \ <a href=\"https://docs.airbyte.io/integrations/destinations/firestore\"\
            >docs</a> if you need help generating this key. Default credentials will\
            \ be used if this field is left empty."
          title: "Credentials JSON"
          airbyte_secret: true
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "append"
    - "overwrite"
- dockerImage: "airbyte/destination-pubsub:0.1.4"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/pubsub"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Google PubSub Destination Spec"
      type: "object"
      required:
      - "project_id"
      - "topic_id"
      - "credentials_json"
      additionalProperties: true
      properties:
        project_id:
          type: "string"
          description: "The GCP project ID for the project containing the target PubSub."
          title: "Project ID"
        topic_id:
          type: "string"
          description: "The PubSub topic ID in the given GCP project ID."
          title: "PubSub Topic ID"
        credentials_json:
          type: "string"
          description: "The contents of the JSON service account key. Check out the\
            \ <a href=\"https://docs.airbyte.io/integrations/destinations/pubsub\"\
            >docs</a> if you need help generating this key."
          title: "Credentials JSON"
          airbyte_secret: true
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "append"
- dockerImage: "airbyte/destination-kafka:0.1.7"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/kafka"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Kafka Destination Spec"
      type: "object"
      required:
      - "bootstrap_servers"
      - "topic_pattern"
      - "protocol"
      - "acks"
      - "enable_idempotence"
      - "compression_type"
      - "batch_size"
      - "linger_ms"
      - "max_in_flight_requests_per_connection"
      - "client_dns_lookup"
      - "buffer_memory"
      - "max_request_size"
      - "retries"
      - "socket_connection_setup_timeout_ms"
      - "socket_connection_setup_timeout_max_ms"
      - "max_block_ms"
      - "request_timeout_ms"
      - "delivery_timeout_ms"
      - "send_buffer_bytes"
      - "receive_buffer_bytes"
      additionalProperties: true
      properties:
        bootstrap_servers:
          title: "Bootstrap Servers"
          description: "A list of host/port pairs to use for establishing the initial\
            \ connection to the Kafka cluster. The client will make use of all servers\
            \ irrespective of which servers are specified here for bootstrapping&mdash;this\
            \ list only impacts the initial hosts used to discover the full set of\
            \ servers. This list should be in the form <code>host1:port1,host2:port2,...</code>.\
            \ Since these servers are just used for the initial connection to discover\
            \ the full cluster membership (which may change dynamically), this list\
            \ need not contain the full set of servers (you may want more than one,\
            \ though, in case a server is down)."
          type: "string"
          examples:
          - "kafka-broker1:9092,kafka-broker2:9092"
        topic_pattern:
          title: "Topic Pattern"
          description: "Topic pattern in which the records will be sent. You can use\
            \ patterns like '{namespace}' and/or '{stream}' to send the message to\
            \ a specific topic based on these values. Notice that the topic name will\
            \ be transformed to a standard naming convention."
          type: "string"
          examples:
          - "sample.topic"
          - "{namespace}.{stream}.sample"
        test_topic:
          title: "Test Topic"
          description: "Topic to test if Airbyte can produce messages."
          type: "string"
          examples:
          - "test.topic"
        sync_producer:
          title: "Sync Producer"
          description: "Wait synchronously until the record has been sent to Kafka."
          type: "boolean"
          default: false
        protocol:
          title: "Protocol"
          type: "object"
          description: "Protocol used to communicate with brokers."
          oneOf:
          - title: "PLAINTEXT"
            required:
            - "security_protocol"
            properties:
              security_protocol:
                type: "string"
                enum:
                - "PLAINTEXT"
                default: "PLAINTEXT"
          - title: "SASL PLAINTEXT"
            required:
            - "security_protocol"
            - "sasl_mechanism"
            - "sasl_jaas_config"
            properties:
              security_protocol:
                type: "string"
                enum:
                - "SASL_PLAINTEXT"
                default: "SASL_PLAINTEXT"
              sasl_mechanism:
                title: "SASL Mechanism"
                description: "SASL mechanism used for client connections. This may\
                  \ be any mechanism for which a security provider is available."
                type: "string"
                default: "PLAIN"
                enum:
                - "PLAIN"
              sasl_jaas_config:
                title: "SASL JAAS Config"
                description: "JAAS login context parameters for SASL connections in\
                  \ the format used by JAAS configuration files."
                type: "string"
                default: ""
                airbyte_secret: true
          - title: "SASL SSL"
            required:
            - "security_protocol"
            - "sasl_mechanism"
            - "sasl_jaas_config"
            properties:
              security_protocol:
                type: "string"
                enum:
                - "SASL_SSL"
                default: "SASL_SSL"
              sasl_mechanism:
                title: "SASL Mechanism"
                description: "SASL mechanism used for client connections. This may\
                  \ be any mechanism for which a security provider is available."
                type: "string"
                default: "GSSAPI"
                enum:
                - "GSSAPI"
                - "OAUTHBEARER"
                - "SCRAM-SHA-256"
                - "SCRAM-SHA-512"
              sasl_jaas_config:
                title: "SASL JAAS Config"
                description: "JAAS login context parameters for SASL connections in\
                  \ the format used by JAAS configuration files."
                type: "string"
                default: ""
                airbyte_secret: true
        client_id:
          title: "Client ID"
          description: "An ID string to pass to the server when making requests. The\
            \ purpose of this is to be able to track the source of requests beyond\
            \ just ip/port by allowing a logical application name to be included in\
            \ server-side request logging."
          type: "string"
          examples:
          - "airbyte-producer"
        acks:
          title: "ACKs"
          description: "The number of acknowledgments the producer requires the leader\
            \ to have received before considering a request complete. This controls\
            \ the  durability of records that are sent."
          type: "string"
          default: "1"
          enum:
          - "0"
          - "1"
          - "all"
        enable_idempotence:
          title: "Enable Idempotence"
          description: "When set to 'true', the producer will ensure that exactly\
            \ one copy of each message is written in the stream. If 'false', producer\
            \ retries due to broker failures, etc., may write duplicates of the retried\
            \ message in the stream."
          type: "boolean"
          default: false
        compression_type:
          title: "Compression Type"
          description: "The compression type for all data generated by the producer."
          type: "string"
          default: "none"
          enum:
          - "none"
          - "gzip"
          - "snappy"
          - "lz4"
          - "zstd"
        batch_size:
          title: "Batch Size"
          description: "The producer will attempt to batch records together into fewer\
            \ requests whenever multiple records are being sent to the same partition."
          type: "integer"
          examples:
          - 16384
        linger_ms:
          title: "Linger ms"
          description: "The producer groups together any records that arrive in between\
            \ request transmissions into a single batched request."
          type: "string"
          examples:
          - 0
        max_in_flight_requests_per_connection:
          title: "Max in Flight Requests per Connection"
          description: "The maximum number of unacknowledged requests the client will\
            \ send on a single connection before blocking. Can be greater than 1,\
            \ and the maximum value supported with idempotency is 5."
          type: "integer"
          examples:
          - 5
        client_dns_lookup:
          title: "Client DNS Lookup"
          description: "Controls how the client uses DNS lookups. If set to use_all_dns_ips,\
            \ connect to each returned IP address in sequence until a successful connection\
            \ is established. After a disconnection, the next IP is used. Once all\
            \ IPs have been used once, the client resolves the IP(s) from the hostname\
            \ again. If set to resolve_canonical_bootstrap_servers_only, resolve each\
            \ bootstrap address into a list of canonical names. After the bootstrap\
            \ phase, this behaves the same as use_all_dns_ips. If set to default (deprecated),\
            \ attempt to connect to the first IP address returned by the lookup, even\
            \ if the lookup returns multiple IP addresses."
          type: "string"
          default: "use_all_dns_ips"
          enum:
          - "default"
          - "use_all_dns_ips"
          - "resolve_canonical_bootstrap_servers_only"
          - "use_all_dns_ips"
        buffer_memory:
          title: "Buffer Memory"
          description: "The total bytes of memory the producer can use to buffer records\
            \ waiting to be sent to the server."
          type: "string"
          examples: 33554432
        max_request_size:
          title: "Max Request Size"
          description: "The maximum size of a request in bytes."
          type: "integer"
          examples:
          - 1048576
        retries:
          title: "Retries"
          description: "Setting a value greater than zero will cause the client to\
            \ resend any record whose send fails with a potentially transient error."
          type: "integer"
          examples:
          - 2147483647
        socket_connection_setup_timeout_ms:
          title: "Socket Connection Setup Timeout"
          description: "The amount of time the client will wait for the socket connection\
            \ to be established."
          type: "string"
          examples:
          - 10000
        socket_connection_setup_timeout_max_ms:
          title: "Socket Connection Setup Max Timeout"
          description: "The maximum amount of time the client will wait for the socket\
            \ connection to be established. The connection setup timeout will increase\
            \ exponentially for each consecutive connection failure up to this maximum."
          type: "string"
          examples:
          - 30000
        max_block_ms:
          title: "Max Block ms"
          description: "The configuration controls how long the KafkaProducer's send(),\
            \ partitionsFor(), initTransactions(), sendOffsetsToTransaction(), commitTransaction()\
            \ and abortTransaction() methods will block."
          type: "string"
          examples:
          - 60000
        request_timeout_ms:
          title: "Request Timeout"
          description: "The configuration controls the maximum amount of time the\
            \ client will wait for the response of a request. If the response is not\
            \ received before the timeout elapses the client will resend the request\
            \ if necessary or fail the request if retries are exhausted."
          type: "integer"
          examples:
          - 30000
        delivery_timeout_ms:
          title: "Delivery Timeout"
          description: "An upper bound on the time to report success or failure after\
            \ a call to 'send()' returns."
          type: "integer"
          examples:
          - 120000
        send_buffer_bytes:
          title: "Send Buffer bytes"
          description: "The size of the TCP send buffer (SO_SNDBUF) to use when sending\
            \ data. If the value is -1, the OS default will be used."
          type: "integer"
          examples:
          - 131072
        receive_buffer_bytes:
          title: "Receive Buffer bytes"
          description: "The size of the TCP receive buffer (SO_RCVBUF) to use when\
            \ reading data. If the value is -1, the OS default will be used."
          type: "integer"
          examples:
          - 32768
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "append"
- dockerImage: "airbyte/destination-kinesis:0.1.2"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/kinesis"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Kinesis Destination Spec"
      type: "object"
      required:
      - "shardCount"
      - "accessKey"
      - "privateKey"
      - "bufferSize"
      additionalProperties: true
      properties:
        endpoint:
          title: "Endpoint"
          description: "AWS Kinesis endpoint."
          type: "string"
          order: 0
        region:
          title: "Region"
          description: "AWS region. Your account determines the Regions that are available\
            \ to you."
          type: "string"
          order: 1
        shardCount:
          title: "Shard Count"
          description: "Number of shards to which the data should be streamed."
          type: "integer"
          default: 5
          order: 2
        accessKey:
          title: "Access Key"
          description: "Generate the AWS Access Key for current user."
          airbyte_secret: true
          type: "string"
          order: 3
        privateKey:
          title: "Private Key"
          description: "The AWS Private Key - a string of numbers and letters that\
            \ are unique for each account, also known as a \"recovery phrase\"."
          airbyte_secret: true
          type: "string"
          order: 4
        bufferSize:
          title: "Buffer Size"
          description: "Buffer size for storing kinesis records before being batch\
            \ streamed."
          type: "integer"
          minimum: 1
          maximum: 500
          default: 100
          order: 5
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "append"
- dockerImage: "airbyte/destination-csv:0.2.9"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/local-csv"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "CSV Destination Spec"
      type: "object"
      required:
      - "destination_path"
      additionalProperties: false
      properties:
        destination_path:
          description: "Path to the directory where csv files will be written. The\
            \ destination uses the local mount \"/local\" and any data files will\
            \ be placed inside that local mount. For more information check out our\
            \ <a href=\"https://docs.airbyte.io/integrations/destinations/local-csv\"\
            >docs</a>"
          type: "string"
          examples:
          - "/local"
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-local-json:0.2.10"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/local-json"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Local Json Destination Spec"
      type: "object"
      required:
      - "destination_path"
      additionalProperties: false
      properties:
        destination_path:
          description: "Path to the directory where json files will be written. The\
            \ files will be placed inside that local mount. For more information check\
            \ out our <a href=\"https://docs.airbyte.io/integrations/destinations/local-json\"\
            >docs</a>"
          title: "Destination Path"
          type: "string"
          examples:
          - "/json_data"
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-mqtt:0.1.1"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/mqtt"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "MQTT Destination Spec"
      type: "object"
      required:
      - "broker_host"
      - "broker_port"
      - "use_tls"
      - "topic_pattern"
      - "publisher_sync"
      - "connect_timeout"
      - "automatic_reconnect"
      - "clean_session"
      - "message_retained"
      - "message_qos"
      additionalProperties: true
      properties:
        broker_host:
          title: "MQTT broker host"
          description: "Host of the broker to connect to."
          type: "string"
        broker_port:
          title: "MQTT broker port"
          description: "Port of the broker."
          type: "integer"
        use_tls:
          title: "Use TLS"
          description: "Whether to use TLS encryption on the connection."
          type: "boolean"
          default: false
        username:
          title: "Username"
          description: "User name to use for the connection."
          type: "string"
        password:
          title: "Password"
          description: "Password to use for the connection."
          type: "string"
        topic_pattern:
          title: "Topic pattern"
          description: "Topic pattern in which the records will be sent. You can use\
            \ patterns like '{namespace}' and/or '{stream}' to send the message to\
            \ a specific topic based on these values. Notice that the topic name will\
            \ be transformed to a standard naming convention."
          type: "string"
          examples:
          - "sample.topic"
          - "{namespace}/{stream}/sample"
        topic_test:
          title: "Test topic"
          description: "Topic to test if Airbyte can produce messages."
          type: "string"
          examples:
          - "test/topic"
        client:
          title: "Client ID"
          description: "A client identifier that is unique on the server being connected\
            \ to."
          type: "string"
          examples:
          - "airbyte-client1"
        publisher_sync:
          title: "Sync publisher"
          description: "Wait synchronously until the record has been sent to the broker."
          type: "boolean"
          default: false
        connect_timeout:
          title: "Connect timeout"
          description: " Maximum time interval (in seconds) the client will wait for\
            \ the network connection to the MQTT server to be established."
          type: "integer"
          default: 30
        automatic_reconnect:
          title: "Automatic reconnect"
          description: "Whether the client will automatically attempt to reconnect\
            \ to the server if the connection is lost."
          type: "boolean"
          default: true
        clean_session:
          title: "Clean session"
          description: "Whether the client and server should remember state across\
            \ restarts and reconnects."
          type: "boolean"
          default: true
        message_retained:
          title: "Message retained"
          description: "Whether or not the publish message should be retained by the\
            \ messaging engine."
          type: "boolean"
          default: false
        message_qos:
          title: "Message QoS"
          description: "Quality of service used for each message to be delivered."
          default: "AT_LEAST_ONCE"
          enum:
          - "AT_MOST_ONCE"
          - "AT_LEAST_ONCE"
          - "EXACTLY_ONCE"
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "append"
- dockerImage: "airbyte/destination-mssql:0.1.16"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/mssql"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "MS SQL Server Destination Spec"
      type: "object"
      required:
      - "host"
      - "port"
      - "username"
      - "database"
      - "schema"
      additionalProperties: true
      properties:
        host:
          title: "Host"
          description: "The host name of the MSSQL database."
          type: "string"
          order: 0
        port:
          title: "Port"
          description: "The port of the MSSQL database."
          type: "integer"
          minimum: 0
          maximum: 65536
          default: 1433
          examples:
          - "1433"
          order: 1
        database:
          title: "DB Name"
          description: "The name of the MSSQL database."
          type: "string"
          order: 2
        schema:
          title: "Default Schema"
          description: "The default schema tables are written to if the source does\
            \ not specify a namespace. The usual value for this field is \"public\"\
            ."
          type: "string"
          examples:
          - "public"
          default: "public"
          order: 3
        username:
          title: "User"
          description: "The username which is used to access the database."
          type: "string"
          order: 4
        password:
          title: "Password"
          description: "The password associated with this username."
          type: "string"
          airbyte_secret: true
          order: 5
        ssl_method:
          title: "SSL Method"
          type: "object"
          description: "The encryption method which is used to communicate with the\
            \ database."
          order: 6
          oneOf:
          - title: "Unencrypted"
            additionalProperties: false
            description: "The data transfer will not be encrypted."
            required:
            - "ssl_method"
            type: "object"
            properties:
              ssl_method:
                type: "string"
                enum:
                - "unencrypted"
                default: "unencrypted"
          - title: "Encrypted (trust server certificate)"
            additionalProperties: false
            description: "Use the certificate provided by the server without verification.\
              \ (For testing purposes only!)"
            required:
            - "ssl_method"
            type: "object"
            properties:
              ssl_method:
                type: "string"
                enum:
                - "encrypted_trust_server_certificate"
                default: "encrypted_trust_server_certificate"
          - title: "Encrypted (verify certificate)"
            additionalProperties: false
            description: "Verify and use the certificate provided by the server."
            required:
            - "ssl_method"
            - "trustStoreName"
            - "trustStorePassword"
            type: "object"
            properties:
              ssl_method:
                type: "string"
                enum:
                - "encrypted_verify_certificate"
                default: "encrypted_verify_certificate"
              hostNameInCertificate:
                title: "Host Name In Certificate"
                type: "string"
                description: "Specifies the host name of the server. The value of\
                  \ this property must match the subject property of the certificate."
                order: 7
        tunnel_method:
          type: "object"
          title: "SSH Tunnel Method"
          description: "Whether to initiate an SSH tunnel before connecting to the\
            \ database, and if so, which kind of authentication to use."
          oneOf:
          - title: "No Tunnel"
            required:
            - "tunnel_method"
            properties:
              tunnel_method:
                description: "No ssh tunnel needed to connect to database"
                type: "string"
                const: "NO_TUNNEL"
                order: 0
          - title: "SSH Key Authentication"
            required:
            - "tunnel_method"
            - "tunnel_host"
            - "tunnel_port"
            - "tunnel_user"
            - "ssh_key"
            properties:
              tunnel_method:
                description: "Connect through a jump server tunnel host using username\
                  \ and ssh key"
                type: "string"
                const: "SSH_KEY_AUTH"
                order: 0
              tunnel_host:
                title: "SSH Tunnel Jump Server Host"
                description: "Hostname of the jump server host that allows inbound\
                  \ ssh tunnel."
                type: "string"
                order: 1
              tunnel_port:
                title: "SSH Connection Port"
                description: "Port on the proxy/jump server that accepts inbound ssh\
                  \ connections."
                type: "integer"
                minimum: 0
                maximum: 65536
                default: 22
                examples:
                - "22"
                order: 2
              tunnel_user:
                title: "SSH Login Username"
                description: "OS-level username for logging into the jump server host."
                type: "string"
                order: 3
              ssh_key:
                title: "SSH Private Key"
                description: "OS-level user account ssh key credentials in RSA PEM\
                  \ format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )"
                type: "string"
                airbyte_secret: true
                multiline: true
                order: 4
          - title: "Password Authentication"
            required:
            - "tunnel_method"
            - "tunnel_host"
            - "tunnel_port"
            - "tunnel_user"
            - "tunnel_user_password"
            properties:
              tunnel_method:
                description: "Connect through a jump server tunnel host using username\
                  \ and password authentication"
                type: "string"
                const: "SSH_PASSWORD_AUTH"
                order: 0
              tunnel_host:
                title: "SSH Tunnel Jump Server Host"
                description: "Hostname of the jump server host that allows inbound\
                  \ ssh tunnel."
                type: "string"
                order: 1
              tunnel_port:
                title: "SSH Connection Port"
                description: "Port on the proxy/jump server that accepts inbound ssh\
                  \ connections."
                type: "integer"
                minimum: 0
                maximum: 65536
                default: 22
                examples:
                - "22"
                order: 2
              tunnel_user:
                title: "SSH Login Username"
                description: "OS-level username for logging into the jump server host"
                type: "string"
                order: 3
              tunnel_user_password:
                title: "Password"
                description: "OS-level password for logging into the jump server host"
                type: "string"
                airbyte_secret: true
                order: 4
    supportsIncremental: true
    supportsNormalization: true
    supportsDBT: true
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
    - "append_dedup"
- dockerImage: "airbyte/destination-meilisearch:0.2.12"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/meilisearch"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "MeiliSearch Destination Spec"
      type: "object"
      required:
      - "host"
      additionalProperties: true
      properties:
        host:
          title: "Host"
          description: "Hostname of the MeiliSearch instance."
          type: "string"
          order: 0
        api_key:
          title: "API Key"
          airbyte_secret: true
          description: "MeiliSearch API Key. See the <a href=\"https://docs.airbyte.io/integrations/destinations/meilisearch\"\
            >docs</a> for more information on how to obtain this key."
          type: "string"
          order: 1
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-mongodb:0.1.4"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/mongodb"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "MongoDB Destination Spec"
      type: "object"
      required:
      - "database"
      - "auth_type"
      additionalProperties: true
      properties:
        instance_type:
          description: "MongoDb instance to connect to. For MongoDB Atlas and Replica\
            \ Set TLS connection is used by default."
          title: "MongoDb Instance Type"
          type: "object"
          order: 0
          oneOf:
          - title: "Standalone MongoDb Instance"
            required:
            - "instance"
            - "host"
            - "port"
            properties:
              instance:
                type: "string"
                enum:
                - "standalone"
                default: "standalone"
              host:
                title: "Host"
                type: "string"
                description: "The Host of a Mongo database to be replicated."
                order: 0
              port:
                title: "Port"
                type: "integer"
                description: "The Port of a Mongo database to be replicated."
                minimum: 0
                maximum: 65536
                default: 27017
                examples:
                - "27017"
                order: 1
              tls:
                title: "TLS Connection"
                type: "boolean"
                description: "Indicates whether TLS encryption protocol will be used\
                  \ to connect to MongoDB. It is recommended to use TLS connection\
                  \ if possible. For more information see <a href=\"https://docs.airbyte.io/integrations/sources/mongodb-v2\"\
                  >documentation</a>."
                default: false
                order: 2
          - title: "Replica Set"
            required:
            - "instance"
            - "server_addresses"
            properties:
              instance:
                type: "string"
                enum:
                - "replica"
                default: "replica"
              server_addresses:
                title: "Server addresses"
                type: "string"
                description: "The members of a replica set. Please specify `host`:`port`\
                  \ of each member seperated by comma."
                examples:
                - "host1:27017,host2:27017,host3:27017"
                order: 0
              replica_set:
                title: "Replica Set"
                type: "string"
                description: "A replica set name."
                order: 1
          - title: "MongoDB Atlas"
            additionalProperties: false
            required:
            - "instance"
            - "cluster_url"
            properties:
              instance:
                type: "string"
                enum:
                - "atlas"
                default: "atlas"
              cluster_url:
                title: "Cluster URL"
                type: "string"
                description: "URL of a cluster to connect to."
                order: 0
        database:
          title: "DB Name"
          description: "Name of the database."
          type: "string"
          order: 2
        auth_type:
          title: "Authorization type"
          type: "object"
          description: "Authorization type."
          oneOf:
          - title: "None"
            additionalProperties: false
            description: "None."
            required:
            - "authorization"
            type: "object"
            properties:
              authorization:
                type: "string"
                const: "none"
          - title: "Login/Password"
            additionalProperties: false
            description: "Login/Password."
            required:
            - "authorization"
            - "username"
            - "password"
            type: "object"
            properties:
              authorization:
                type: "string"
                const: "login/password"
              username:
                title: "User"
                description: "Username to use to access the database."
                type: "string"
                order: 1
              password:
                title: "Password"
                description: "Password associated with the username."
                type: "string"
                airbyte_secret: true
                order: 2
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-mysql:0.1.18"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/mysql"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "MySQL Destination Spec"
      type: "object"
      required:
      - "host"
      - "port"
      - "username"
      - "database"
      additionalProperties: true
      properties:
        host:
          title: "Host"
          description: "Hostname of the database."
          type: "string"
          order: 0
        port:
          title: "Port"
          description: "Port of the database."
          type: "integer"
          minimum: 0
          maximum: 65536
          default: 3306
          examples:
          - "3306"
          order: 1
        database:
          title: "DB Name"
          description: "Name of the database."
          type: "string"
          order: 2
        username:
          title: "User"
          description: "Username to use to access the database."
          type: "string"
          order: 3
        password:
          title: "Password"
          description: "Password associated with the username."
          type: "string"
          airbyte_secret: true
          order: 4
        ssl:
          title: "SSL Connection"
          description: "Encrypt data using SSL."
          type: "boolean"
          default: true
          order: 5
        jdbc_url_params:
          description: "Additional properties to pass to the JDBC URL string when\
            \ connecting to the database formatted as 'key=value' pairs separated\
            \ by the symbol '&'. (example: key1=value1&key2=value2&key3=value3)."
          title: "JDBC URL Params"
          type: "string"
          order: 6
        tunnel_method:
          type: "object"
          title: "SSH Tunnel Method"
          description: "Whether to initiate an SSH tunnel before connecting to the\
            \ database, and if so, which kind of authentication to use."
          oneOf:
          - title: "No Tunnel"
            required:
            - "tunnel_method"
            properties:
              tunnel_method:
                description: "No ssh tunnel needed to connect to database"
                type: "string"
                const: "NO_TUNNEL"
                order: 0
          - title: "SSH Key Authentication"
            required:
            - "tunnel_method"
            - "tunnel_host"
            - "tunnel_port"
            - "tunnel_user"
            - "ssh_key"
            properties:
              tunnel_method:
                description: "Connect through a jump server tunnel host using username\
                  \ and ssh key"
                type: "string"
                const: "SSH_KEY_AUTH"
                order: 0
              tunnel_host:
                title: "SSH Tunnel Jump Server Host"
                description: "Hostname of the jump server host that allows inbound\
                  \ ssh tunnel."
                type: "string"
                order: 1
              tunnel_port:
                title: "SSH Connection Port"
                description: "Port on the proxy/jump server that accepts inbound ssh\
                  \ connections."
                type: "integer"
                minimum: 0
                maximum: 65536
                default: 22
                examples:
                - "22"
                order: 2
              tunnel_user:
                title: "SSH Login Username"
                description: "OS-level username for logging into the jump server host."
                type: "string"
                order: 3
              ssh_key:
                title: "SSH Private Key"
                description: "OS-level user account ssh key credentials in RSA PEM\
                  \ format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )"
                type: "string"
                airbyte_secret: true
                multiline: true
                order: 4
          - title: "Password Authentication"
            required:
            - "tunnel_method"
            - "tunnel_host"
            - "tunnel_port"
            - "tunnel_user"
            - "tunnel_user_password"
            properties:
              tunnel_method:
                description: "Connect through a jump server tunnel host using username\
                  \ and password authentication"
                type: "string"
                const: "SSH_PASSWORD_AUTH"
                order: 0
              tunnel_host:
                title: "SSH Tunnel Jump Server Host"
                description: "Hostname of the jump server host that allows inbound\
                  \ ssh tunnel."
                type: "string"
                order: 1
              tunnel_port:
                title: "SSH Connection Port"
                description: "Port on the proxy/jump server that accepts inbound ssh\
                  \ connections."
                type: "integer"
                minimum: 0
                maximum: 65536
                default: 22
                examples:
                - "22"
                order: 2
              tunnel_user:
                title: "SSH Login Username"
                description: "OS-level username for logging into the jump server host"
                type: "string"
                order: 3
              tunnel_user_password:
                title: "Password"
                description: "OS-level password for logging into the jump server host"
                type: "string"
                airbyte_secret: true
                order: 4
    supportsIncremental: true
    supportsNormalization: true
    supportsDBT: true
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-oracle:0.1.15"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/oracle"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Oracle Destination Spec"
      type: "object"
      required:
      - "host"
      - "port"
      - "username"
      - "sid"
      additionalProperties: true
      properties:
        host:
          title: "Host"
          description: "The hostname of the database."
          type: "string"
          order: 0
        port:
          title: "Port"
          description: "The port of the database."
          type: "integer"
          minimum: 0
          maximum: 65536
          default: 1521
          examples:
          - "1521"
          order: 1
        sid:
          title: "SID"
          description: "The System Identifier uniquely distinguishes the instance\
            \ from any other instance on the same computer."
          type: "string"
          order: 2
        username:
          title: "User"
          description: "The username to access the database. This user must have CREATE\
            \ USER privileges in the database."
          type: "string"
          order: 3
        password:
          title: "Password"
          description: "The password associated with the username."
          type: "string"
          airbyte_secret: true
          order: 4
        schema:
          title: "Default Schema"
          description: "The default schema is used as the target schema for all statements\
            \ issued from the connection that do not explicitly specify a schema name.\
            \ The usual value for this field is \"airbyte\".  In Oracle, schemas and\
            \ users are the same thing, so the \"user\" parameter is used as the login\
            \ credentials and this is used for the default Airbyte message schema."
          type: "string"
          examples:
          - "airbyte"
          default: "airbyte"
          order: 5
        encryption:
          title: "Encryption"
          type: "object"
          description: "The encryption method which is used when communicating with\
            \ the database."
          order: 6
          oneOf:
          - title: "Unencrypted"
            additionalProperties: false
            description: "Data transfer will not be encrypted."
            required:
            - "encryption_method"
            properties:
              encryption_method:
                type: "string"
                const: "unencrypted"
                enum:
                - "unencrypted"
                default: "unencrypted"
          - title: "Native Network Encryption (NNE)"
            additionalProperties: false
            description: "The native network encryption gives you the ability to encrypt\
              \ database connections, without the configuration overhead of TCP/IP\
              \ and SSL/TLS and without the need to open and listen on different ports."
            required:
            - "encryption_method"
            properties:
              encryption_method:
                type: "string"
                const: "client_nne"
                enum:
                - "client_nne"
                default: "client_nne"
              encryption_algorithm:
                type: "string"
                description: "This parameter defines the database encryption algorithm."
                title: "Encryption Algorithm"
                default: "AES256"
                enum:
                - "AES256"
                - "RC4_56"
                - "3DES168"
          - title: "TLS Encrypted (verify certificate)"
            additionalProperties: false
            description: "Verify and use the certificate provided by the server."
            required:
            - "encryption_method"
            - "ssl_certificate"
            properties:
              encryption_method:
                type: "string"
                const: "encrypted_verify_certificate"
                enum:
                - "encrypted_verify_certificate"
                default: "encrypted_verify_certificate"
              ssl_certificate:
                title: "SSL PEM file"
                description: "Privacy Enhanced Mail (PEM) files are concatenated certificate\
                  \ containers frequently used in certificate installations."
                type: "string"
                airbyte_secret: true
                multiline: true
        tunnel_method:
          type: "object"
          title: "SSH Tunnel Method"
          description: "Whether to initiate an SSH tunnel before connecting to the\
            \ database, and if so, which kind of authentication to use."
          oneOf:
          - title: "No Tunnel"
            required:
            - "tunnel_method"
            properties:
              tunnel_method:
                description: "No ssh tunnel needed to connect to database"
                type: "string"
                const: "NO_TUNNEL"
                order: 0
          - title: "SSH Key Authentication"
            required:
            - "tunnel_method"
            - "tunnel_host"
            - "tunnel_port"
            - "tunnel_user"
            - "ssh_key"
            properties:
              tunnel_method:
                description: "Connect through a jump server tunnel host using username\
                  \ and ssh key"
                type: "string"
                const: "SSH_KEY_AUTH"
                order: 0
              tunnel_host:
                title: "SSH Tunnel Jump Server Host"
                description: "Hostname of the jump server host that allows inbound\
                  \ ssh tunnel."
                type: "string"
                order: 1
              tunnel_port:
                title: "SSH Connection Port"
                description: "Port on the proxy/jump server that accepts inbound ssh\
                  \ connections."
                type: "integer"
                minimum: 0
                maximum: 65536
                default: 22
                examples:
                - "22"
                order: 2
              tunnel_user:
                title: "SSH Login Username"
                description: "OS-level username for logging into the jump server host."
                type: "string"
                order: 3
              ssh_key:
                title: "SSH Private Key"
                description: "OS-level user account ssh key credentials in RSA PEM\
                  \ format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )"
                type: "string"
                airbyte_secret: true
                multiline: true
                order: 4
          - title: "Password Authentication"
            required:
            - "tunnel_method"
            - "tunnel_host"
            - "tunnel_port"
            - "tunnel_user"
            - "tunnel_user_password"
            properties:
              tunnel_method:
                description: "Connect through a jump server tunnel host using username\
                  \ and password authentication"
                type: "string"
                const: "SSH_PASSWORD_AUTH"
                order: 0
              tunnel_host:
                title: "SSH Tunnel Jump Server Host"
                description: "Hostname of the jump server host that allows inbound\
                  \ ssh tunnel."
                type: "string"
                order: 1
              tunnel_port:
                title: "SSH Connection Port"
                description: "Port on the proxy/jump server that accepts inbound ssh\
                  \ connections."
                type: "integer"
                minimum: 0
                maximum: 65536
                default: 22
                examples:
                - "22"
                order: 2
              tunnel_user:
                title: "SSH Login Username"
                description: "OS-level username for logging into the jump server host"
                type: "string"
                order: 3
              tunnel_user_password:
                title: "Password"
                description: "OS-level password for logging into the jump server host"
                type: "string"
                airbyte_secret: true
                order: 4
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-postgres:0.3.18"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/postgres"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Postgres Destination Spec"
      type: "object"
      required:
      - "host"
      - "port"
      - "username"
      - "database"
      - "schema"
      additionalProperties: true
      properties:
        host:
          title: "Host"
          description: "Hostname of the database."
          type: "string"
          order: 0
        port:
          title: "Port"
          description: "Port of the database."
          type: "integer"
          minimum: 0
          maximum: 65536
          default: 5432
          examples:
          - "5432"
          order: 1
        database:
          title: "DB Name"
          description: "Name of the database."
          type: "string"
          order: 2
        schema:
          title: "Default Schema"
          description: "The default schema tables are written to if the source does\
            \ not specify a namespace. The usual value for this field is \"public\"\
            ."
          type: "string"
          examples:
          - "public"
          default: "public"
          order: 3
        username:
          title: "User"
          description: "Username to use to access the database."
          type: "string"
          order: 4
        password:
          title: "Password"
          description: "Password associated with the username."
          type: "string"
          airbyte_secret: true
          order: 5
        ssl:
          title: "SSL Connection"
          description: "Encrypt data using SSL."
          type: "boolean"
          default: false
          order: 6
        tunnel_method:
          type: "object"
          title: "SSH Tunnel Method"
          description: "Whether to initiate an SSH tunnel before connecting to the\
            \ database, and if so, which kind of authentication to use."
          oneOf:
          - title: "No Tunnel"
            required:
            - "tunnel_method"
            properties:
              tunnel_method:
                description: "No ssh tunnel needed to connect to database"
                type: "string"
                const: "NO_TUNNEL"
                order: 0
          - title: "SSH Key Authentication"
            required:
            - "tunnel_method"
            - "tunnel_host"
            - "tunnel_port"
            - "tunnel_user"
            - "ssh_key"
            properties:
              tunnel_method:
                description: "Connect through a jump server tunnel host using username\
                  \ and ssh key"
                type: "string"
                const: "SSH_KEY_AUTH"
                order: 0
              tunnel_host:
                title: "SSH Tunnel Jump Server Host"
                description: "Hostname of the jump server host that allows inbound\
                  \ ssh tunnel."
                type: "string"
                order: 1
              tunnel_port:
                title: "SSH Connection Port"
                description: "Port on the proxy/jump server that accepts inbound ssh\
                  \ connections."
                type: "integer"
                minimum: 0
                maximum: 65536
                default: 22
                examples:
                - "22"
                order: 2
              tunnel_user:
                title: "SSH Login Username"
                description: "OS-level username for logging into the jump server host."
                type: "string"
                order: 3
              ssh_key:
                title: "SSH Private Key"
                description: "OS-level user account ssh key credentials in RSA PEM\
                  \ format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )"
                type: "string"
                airbyte_secret: true
                multiline: true
                order: 4
          - title: "Password Authentication"
            required:
            - "tunnel_method"
            - "tunnel_host"
            - "tunnel_port"
            - "tunnel_user"
            - "tunnel_user_password"
            properties:
              tunnel_method:
                description: "Connect through a jump server tunnel host using username\
                  \ and password authentication"
                type: "string"
                const: "SSH_PASSWORD_AUTH"
                order: 0
              tunnel_host:
                title: "SSH Tunnel Jump Server Host"
                description: "Hostname of the jump server host that allows inbound\
                  \ ssh tunnel."
                type: "string"
                order: 1
              tunnel_port:
                title: "SSH Connection Port"
                description: "Port on the proxy/jump server that accepts inbound ssh\
                  \ connections."
                type: "integer"
                minimum: 0
                maximum: 65536
                default: 22
                examples:
                - "22"
                order: 2
              tunnel_user:
                title: "SSH Login Username"
                description: "OS-level username for logging into the jump server host"
                type: "string"
                order: 3
              tunnel_user_password:
                title: "Password"
                description: "OS-level password for logging into the jump server host"
                type: "string"
                airbyte_secret: true
                order: 4
    supportsIncremental: true
    supportsNormalization: true
    supportsDBT: true
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
    - "append_dedup"
- dockerImage: "airbyte/destination-pulsar:0.1.1"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/pulsar"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Pulsar Destination Spec"
      type: "object"
      required:
      - "brokers"
      - "use_tls"
      - "topic_type"
      - "topic_tenant"
      - "topic_namespace"
      - "topic_pattern"
      - "compression_type"
      - "send_timeout_ms"
      - "max_pending_messages"
      - "max_pending_messages_across_partitions"
      - "batching_enabled"
      - "batching_max_messages"
      - "batching_max_publish_delay"
      - "block_if_queue_full"
      additionalProperties: true
      properties:
        brokers:
          title: "Pulsar brokers"
          description: "A list of host/port pairs to use for establishing the initial\
            \ connection to the Pulsar cluster."
          type: "string"
          examples:
          - "broker1:6650,broker2:6650"
        use_tls:
          title: "Use TLS"
          description: "Whether to use TLS encryption on the connection."
          type: "boolean"
          default: false
        topic_type:
          title: "Topic type"
          description: "It identifies type of topic. Pulsar supports two kind of topics:\
            \ persistent and non-persistent. In persistent topic, all messages are\
            \ durably persisted on disk (that means on multiple disks unless the broker\
            \ is standalone), whereas non-persistent topic does not persist message\
            \ into storage disk."
          type: "string"
          default: "persistent"
          enum:
          - "persistent"
          - "non-persistent"
        topic_tenant:
          title: "Topic tenant"
          description: "The topic tenant within the instance. Tenants are essential\
            \ to multi-tenancy in Pulsar, and spread across clusters."
          type: "string"
          default: "public"
          examples:
          - "public"
        topic_namespace:
          title: "Topic namespace"
          description: "The administrative unit of the topic, which acts as a grouping\
            \ mechanism for related topics. Most topic configuration is performed\
            \ at the namespace level. Each tenant has one or multiple namespaces."
          type: "string"
          default: "default"
          examples:
          - "default"
        topic_pattern:
          title: "Topic pattern"
          description: "Topic pattern in which the records will be sent. You can use\
            \ patterns like '{namespace}' and/or '{stream}' to send the message to\
            \ a specific topic based on these values. Notice that the topic name will\
            \ be transformed to a standard naming convention."
          type: "string"
          examples:
          - "sample.topic"
          - "{namespace}.{stream}.sample"
        topic_test:
          title: "Test topic"
          description: "Topic to test if Airbyte can produce messages."
          type: "string"
          examples:
          - "test.topic"
        producer_name:
          title: "Producer name"
          description: "Name for the producer. If not filled, the system will generate\
            \ a globally unique name which can be accessed with."
          type: "string"
          examples:
          - "airbyte-producer"
        producer_sync:
          title: "Sync producer"
          description: "Wait synchronously until the record has been sent to Pulsar."
          type: "boolean"
          default: false
        compression_type:
          title: "Compression type"
          description: "Compression type for the producer."
          type: "string"
          default: "NONE"
          enum:
          - "NONE"
          - "LZ4"
          - "ZLIB"
          - "ZSTD"
          - "SNAPPY"
        send_timeout_ms:
          title: "Message send timeout"
          description: "If a message is not acknowledged by a server before the send-timeout\
            \ expires, an error occurs (in ms)."
          type: "integer"
          default: 30000
        max_pending_messages:
          title: "Max pending messages"
          description: "The maximum size of a queue holding pending messages."
          type: "integer"
          default: 1000
        max_pending_messages_across_partitions:
          title: "Max pending messages across partitions"
          description: "The maximum number of pending messages across partitions."
          type: "integer"
          default: 50000
        batching_enabled:
          title: "Enable batching"
          description: "Control whether automatic batching of messages is enabled\
            \ for the producer."
          type: "boolean"
          default: true
        batching_max_messages:
          title: "Batching max messages"
          description: "Maximum number of messages permitted in a batch."
          type: "integer"
          default: 1000
        batching_max_publish_delay:
          title: "Batching max publish delay"
          description: " Time period in milliseconds within which the messages sent\
            \ will be batched."
          type: "integer"
          default: 1
        block_if_queue_full:
          title: "Block if queue is full"
          description: "If the send operation should block when the outgoing message\
            \ queue is full."
          type: "boolean"
          default: false
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "append"
- dockerImage: "airbyte/destination-rabbitmq:0.1.0"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/rabbitmq"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Destination Rabbitmq"
      type: "object"
      required:
      - "host"
      - "routing_key"
      additionalProperties: false
      properties:
        ssl:
          type: "boolean"
          description: "SSL enabled."
          default: true
        host:
          type: "string"
          description: "The RabbitMQ host name."
        port:
          type: "integer"
          description: "The RabbitMQ port."
        virtual_host:
          type: "string"
          description: "The RabbitMQ virtual host name."
        username:
          type: "string"
          description: "The username to connect."
        password:
          type: "string"
          description: "The password to connect."
        exchange:
          type: "string"
          description: "The exchange name."
        routing_key:
          type: "string"
          description: "The routing key."
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "append"
- dockerImage: "airbyte/destination-redis:0.1.1"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/redis"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Redis Destination Spec"
      type: "object"
      required:
      - "host"
      - "port"
      - "username"
      - "password"
      - "cache_type"
      additionalProperties: false
      properties:
        host:
          title: "Host"
          description: "Redis host to connect to."
          type: "string"
          examples:
          - "localhost,127.0.0.1"
          order: 1
        port:
          title: "Port"
          description: "Port of Redis."
          type: "integer"
          minimum: 0
          maximum: 65536
          default: 6379
          order: 2
        username:
          title: "Username"
          description: "Username associated with Redis."
          type: "string"
          order: 3
        password:
          title: "Password"
          description: "Password associated with Redis."
          type: "string"
          airbyte_secret: true
          order: 4
        cache_type:
          title: "Cache type"
          type: "string"
          default: "hash"
          description: "Redis cache type to store data in."
          enum:
          - "hash"
          order: 5
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-redshift:0.3.32"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/redshift"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Redshift Destination Spec"
      type: "object"
      required:
      - "host"
      - "port"
      - "database"
      - "username"
      - "password"
      - "schema"
      additionalProperties: true
      properties:
        host:
          description: "Host Endpoint of the Redshift Cluster (must include the cluster-id,\
            \ region and end with .redshift.amazonaws.com)"
          type: "string"
          title: "Host"
        port:
          description: "Port of the database."
          type: "integer"
          minimum: 0
          maximum: 65536
          default: 5439
          examples:
          - "5439"
          title: "Port"
        username:
          description: "Username to use to access the database."
          type: "string"
          title: "Username"
        password:
          description: "Password associated with the username."
          type: "string"
          airbyte_secret: true
          title: "Password"
        database:
          description: "Name of the database."
          type: "string"
          title: "Database"
        schema:
          description: "The default schema tables are written to if the source does\
            \ not specify a namespace. Unless specifically configured, the usual value\
            \ for this field is \"public\"."
          type: "string"
          examples:
          - "public"
          default: "public"
          title: "Default Schema"
        s3_bucket_name:
          title: "S3 Bucket Name"
          type: "string"
          description: "The name of the staging S3 bucket to use if utilising a COPY\
            \ strategy. COPY is recommended for production workloads for better speed\
            \ and scalability. See <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/c_loading-data-best-practices.html\"\
            >AWS docs</a> for more details."
          examples:
          - "airbyte.staging"
        s3_bucket_path:
          title: "S3 Bucket Path"
          type: "string"
          description: "The directory under the S3 bucket where data will be written.\
            \ If not provided, then defaults to the root directory."
          examples:
          - "data_sync/test"
        s3_bucket_region:
          title: "S3 Bucket Region"
          type: "string"
          default: ""
          description: "The region of the S3 staging bucket to use if utilising a\
            \ copy strategy."
          enum:
          - ""
          - "us-east-1"
          - "us-east-2"
          - "us-west-1"
          - "us-west-2"
          - "af-south-1"
          - "ap-east-1"
          - "ap-south-1"
          - "ap-northeast-1"
          - "ap-northeast-2"
          - "ap-northeast-3"
          - "ap-southeast-1"
          - "ap-southeast-2"
          - "ca-central-1"
          - "cn-north-1"
          - "cn-northwest-1"
          - "eu-central-1"
          - "eu-north-1"
          - "eu-south-1"
          - "eu-west-1"
          - "eu-west-2"
          - "eu-west-3"
          - "sa-east-1"
          - "me-south-1"
        access_key_id:
          type: "string"
          description: "The Access Key Id granting allow one to access the above S3\
            \ staging bucket. Airbyte requires Read and Write permissions to the given\
            \ bucket."
          title: "S3 Key Id"
          airbyte_secret: true
        secret_access_key:
          type: "string"
          description: "The corresponding secret to the above access key id."
          title: "S3 Access Key"
          airbyte_secret: true
        part_size:
          type: "integer"
          minimum: 10
          maximum: 100
          examples:
          - "10"
          description: "Optional. Increase this if syncing tables larger than 100GB.\
            \ Only relevant for COPY. Files are streamed to S3 in parts. This determines\
            \ the size of each part, in MBs. As S3 has a limit of 10,000 parts per\
            \ file, part size affects the table size. This is 10MB by default, resulting\
            \ in a default limit of 100GB tables. Note, a larger part size will result\
            \ in larger memory requirements. A rule of thumb is to multiply the part\
            \ size by 10 to get the memory requirement. Modify this with care."
          title: "Stream Part Size"
        purge_staging_data:
          title: "Purge Staging Files and Tables"
          type: "boolean"
          description: "Whether to delete the staging files from S3 after completing\
            \ the sync. See the docs for details. Only relevant for COPY. Defaults\
            \ to true."
          default: true
    supportsIncremental: true
    supportsNormalization: true
    supportsDBT: true
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
    - "append_dedup"
- dockerImage: "airbyte/destination-rockset:0.1.1"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/rockset"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Rockset Destination Spec"
      type: "object"
      required:
      - "api_key"
      - "workspace"
      additionalProperties: false
      properties:
        api_key:
          title: "Api Key"
          description: "Rockset api key"
          type: "string"
          order: 0
          airbyte_secret: true
        workspace:
          title: "Workspace"
          description: "The Rockset workspace in which collections will be created\
            \ + written to."
          type: "string"
          examples:
          - "commons"
          - "my_workspace"
          default: "commons"
          airbyte_secret: false
          order: 1
        api_server:
          title: "Api Server"
          description: "Rockset api URL"
          type: "string"
          airbyte_secret: false
          default: "https://api.rs2.usw2.rockset.com"
          pattern: "^https:\\/\\/.*.rockset.com$"
          order: 2
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "append"
    - "overwrite"
- dockerImage: "airbyte/destination-s3:0.3.3"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/s3"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "S3 Destination Spec"
      type: "object"
      required:
      - "s3_bucket_name"
      - "s3_bucket_path"
      - "s3_bucket_region"
      - "format"
      additionalProperties: false
      properties:
        s3_endpoint:
          title: "Endpoint"
          type: "string"
          default: ""
          description: "This is your S3 endpoint url.(if you are working with AWS\
            \ S3, just leave empty)."
          examples:
          - "http://localhost:9000"
          order: 0
        s3_bucket_name:
          title: "S3 Bucket Name"
          type: "string"
          description: "The name of the S3 bucket."
          examples:
          - "airbyte_sync"
          order: 1
        s3_bucket_path:
          description: "Directory under the S3 bucket where data will be written."
          type: "string"
          examples:
          - "data_sync/test"
          order: 2
        s3_path_format:
          description: "Format string on how data will be organized inside the S3\
            \ bucket directory"
          type: "string"
          examples:
          - "${NAMESPACE}/${STREAM_NAME}/${YEAR}_${MONTH}_${DAY}_${EPOCH}_"
          order: 3
        s3_bucket_region:
          title: "S3 Bucket Region"
          type: "string"
          default: ""
          description: "The region of the S3 bucket."
          enum:
          - ""
          - "us-east-1"
          - "us-east-2"
          - "us-west-1"
          - "us-west-2"
          - "af-south-1"
          - "ap-east-1"
          - "ap-south-1"
          - "ap-northeast-1"
          - "ap-northeast-2"
          - "ap-northeast-3"
          - "ap-southeast-1"
          - "ap-southeast-2"
          - "ca-central-1"
          - "cn-north-1"
          - "cn-northwest-1"
          - "eu-central-1"
          - "eu-north-1"
          - "eu-south-1"
          - "eu-west-1"
          - "eu-west-2"
          - "eu-west-3"
          - "sa-east-1"
          - "me-south-1"
          - "us-gov-east-1"
          - "us-gov-west-1"
          order: 4
        access_key_id:
          type: "string"
          description: "The access key id to access the S3 bucket. Airbyte requires\
            \ Read and Write permissions to the given bucket, if not set, Airbyte\
            \ will rely on Instance Profile."
          title: "S3 Key Id"
          airbyte_secret: true
          examples:
          - "A012345678910EXAMPLE"
          order: 5
        secret_access_key:
          type: "string"
          description: "The corresponding secret to the access key id, if S3 Key Id\
            \ is set, then S3 Access Key must also be provided"
          title: "S3 Access Key"
          airbyte_secret: true
          examples:
          - "a012345678910ABCDEFGH/AbCdEfGhEXAMPLEKEY"
          order: 6
        format:
          title: "Output Format"
          type: "object"
          description: "Output data format"
          oneOf:
          - title: "Avro: Apache Avro"
            required:
            - "format_type"
            - "compression_codec"
            properties:
              format_type:
                type: "string"
                enum:
                - "Avro"
                default: "Avro"
              compression_codec:
                title: "Compression Codec"
                description: "The compression algorithm used to compress data. Default\
                  \ to no compression."
                type: "object"
                oneOf:
                - title: "no compression"
                  required:
                  - "codec"
                  properties:
                    codec:
                      type: "string"
                      enum:
                      - "no compression"
                      default: "no compression"
                - title: "Deflate"
                  required:
                  - "codec"
                  - "compression_level"
                  properties:
                    codec:
                      type: "string"
                      enum:
                      - "Deflate"
                      default: "Deflate"
                    compression_level:
                      title: "Deflate level"
                      description: "0: no compression & fastest, 9: best compression\
                        \ & slowest."
                      type: "integer"
                      default: 0
                      minimum: 0
                      maximum: 9
                - title: "bzip2"
                  required:
                  - "codec"
                  properties:
                    codec:
                      type: "string"
                      enum:
                      - "bzip2"
                      default: "bzip2"
                - title: "xz"
                  required:
                  - "codec"
                  - "compression_level"
                  properties:
                    codec:
                      type: "string"
                      enum:
                      - "xz"
                      default: "xz"
                    compression_level:
                      title: "Compression level"
                      description: "See <a href=\"https://commons.apache.org/proper/commons-compress/apidocs/org/apache/commons/compress/compressors/xz/XZCompressorOutputStream.html#XZCompressorOutputStream-java.io.OutputStream-int-\"\
                        >here</a> for details."
                      type: "integer"
                      default: 6
                      minimum: 0
                      maximum: 9
                - title: "zstandard"
                  required:
                  - "codec"
                  - "compression_level"
                  properties:
                    codec:
                      type: "string"
                      enum:
                      - "zstandard"
                      default: "zstandard"
                    compression_level:
                      title: "Compression level"
                      description: "Negative levels are 'fast' modes akin to lz4 or\
                        \ snappy, levels above 9 are generally for archival purposes,\
                        \ and levels above 18 use a lot of memory."
                      type: "integer"
                      default: 3
                      minimum: -5
                      maximum: 22
                    include_checksum:
                      title: "Include checksum"
                      description: "If true, include a checksum with each data block."
                      type: "boolean"
                      default: false
                - title: "snappy"
                  required:
                  - "codec"
                  properties:
                    codec:
                      type: "string"
                      enum:
                      - "snappy"
                      default: "snappy"
              part_size_mb:
                title: "Block Size (MB) for Amazon S3 multipart upload"
                description: "This is the size of a \"Part\" being buffered in memory.\
                  \ It limits the memory usage when writing. Larger values will allow\
                  \ to upload a bigger files and improve the speed, but consumes9\
                  \ more memory. Allowed values: min=5MB, max=525MB Default: 5MB."
                type: "integer"
                default: 5
                examples:
                - 5
          - title: "CSV: Comma-Separated Values"
            required:
            - "format_type"
            - "flattening"
            properties:
              format_type:
                type: "string"
                enum:
                - "CSV"
                default: "CSV"
              flattening:
                type: "string"
                title: "Normalization (Flattening)"
                description: "Whether the input json data should be normalized (flattened)\
                  \ in the output CSV. Please refer to docs for details."
                default: "No flattening"
                enum:
                - "No flattening"
                - "Root level flattening"
              part_size_mb:
                title: "Block Size (MB) for Amazon S3 multipart upload"
                description: "This is the size of a \"Part\" being buffered in memory.\
                  \ It limits the memory usage when writing. Larger values will allow\
                  \ to upload a bigger files and improve the speed, but consumes9\
                  \ more memory. Allowed values: min=5MB, max=525MB Default: 5MB."
                type: "integer"
                default: 5
                examples:
                - 5
              compression:
                title: "Compression"
                type: "object"
                description: "Whether the output files should be compressed. If compression\
                  \ is selected, the output filename will have an extra extension\
                  \ (GZIP: \".csv.gz\")."
                oneOf:
                - title: "No Compression"
                  requires:
                  - "compression_type"
                  properties:
                    compression_type:
                      type: "string"
                      enum:
                      - "No Compression"
                      default: "No Compression"
                - title: "GZIP"
                  requires:
                  - "compression_type"
                  properties:
                    compression_type:
                      type: "string"
                      enum:
                      - "GZIP"
                      default: "GZIP"
          - title: "JSON Lines: newline-delimited JSON"
            required:
            - "format_type"
            properties:
              format_type:
                type: "string"
                enum:
                - "JSONL"
                default: "JSONL"
              part_size_mb:
                title: "Block Size (MB) for Amazon S3 multipart upload"
                description: "This is the size of a \"Part\" being buffered in memory.\
                  \ It limits the memory usage when writing. Larger values will allow\
                  \ to upload a bigger files and improve the speed, but consumes9\
                  \ more memory. Allowed values: min=5MB, max=525MB Default: 5MB."
                type: "integer"
                default: 5
                examples:
                - 5
              compression:
                title: "Compression"
                type: "object"
                description: "Whether the output files should be compressed. If compression\
                  \ is selected, the output filename will have an extra extension\
                  \ (GZIP: \".jsonl.gz\")."
                oneOf:
                - title: "No Compression"
                  requires: "compression_type"
                  properties:
                    compression_type:
                      type: "string"
                      enum:
                      - "No Compression"
                      default: "No Compression"
                - title: "GZIP"
                  requires: "compression_type"
                  properties:
                    compression_type:
                      type: "string"
                      enum:
                      - "GZIP"
                      default: "GZIP"
          - title: "Parquet: Columnar Storage"
            required:
            - "format_type"
            properties:
              format_type:
                type: "string"
                enum:
                - "Parquet"
                default: "Parquet"
              compression_codec:
                title: "Compression Codec"
                description: "The compression algorithm used to compress data pages."
                type: "string"
                enum:
                - "UNCOMPRESSED"
                - "SNAPPY"
                - "GZIP"
                - "LZO"
                - "BROTLI"
                - "LZ4"
                - "ZSTD"
                default: "UNCOMPRESSED"
              block_size_mb:
                title: "Block Size (Row Group Size) (MB)"
                description: "This is the size of a row group being buffered in memory.\
                  \ It limits the memory usage when writing. Larger values will improve\
                  \ the IO when reading, but consume more memory when writing. Default:\
                  \ 128 MB."
                type: "integer"
                default: 128
                examples:
                - 128
              max_padding_size_mb:
                title: "Max Padding Size (MB)"
                description: "Maximum size allowed as padding to align row groups.\
                  \ This is also the minimum size of a row group. Default: 8 MB."
                type: "integer"
                default: 8
                examples:
                - 8
              page_size_kb:
                title: "Page Size (KB)"
                description: "The page size is for compression. A block is composed\
                  \ of pages. A page is the smallest unit that must be read fully\
                  \ to access a single record. If this value is too small, the compression\
                  \ will deteriorate. Default: 1024 KB."
                type: "integer"
                default: 1024
                examples:
                - 1024
              dictionary_page_size_kb:
                title: "Dictionary Page Size (KB)"
                description: "There is one dictionary page per column per row group\
                  \ when dictionary encoding is used. The dictionary page size works\
                  \ like the page size but for dictionary. Default: 1024 KB."
                type: "integer"
                default: 1024
                examples:
                - 1024
              dictionary_encoding:
                title: "Dictionary Encoding"
                description: "Default: true."
                type: "boolean"
                default: true
          order: 7
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-sftp-json:0.1.0"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/sftp-json"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Destination SFTP JSON"
      type: "object"
      required:
      - "host"
      - "username"
      - "password"
      - "destination_path"
      additionalProperties: false
      properties:
        host:
          title: "Host"
          description: "Hostname of the SFTP server."
          type: "string"
          order: 0
        port:
          title: "Port"
          description: "Port of the SFTP server."
          type: "integer"
          minimum: 0
          maximum: 65536
          default: 22
          examples:
          - 22
          order: 1
        username:
          title: "User"
          description: "Username to use to access the SFTP server."
          type: "string"
          order: 2
        password:
          title: "Password"
          description: "Password associated with the username."
          type: "string"
          airbyte_secret: true
          order: 3
        destination_path:
          title: "Destination path"
          type: "string"
          description: "Path to the directory where json files will be written."
          examples:
          - "/json_data"
          order: 4
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "airbyte/destination-snowflake:0.4.24"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/snowflake"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Snowflake Destination Spec"
      type: "object"
      required:
      - "host"
      - "role"
      - "warehouse"
      - "database"
      - "schema"
      - "username"
      additionalProperties: true
      properties:
        host:
          description: "The host domain of the snowflake instance (must include the\
            \ account, region, cloud environment, and end with snowflakecomputing.com).\
            \ The account identifier differs depending on your cloud region, be sure\
            \ to verify with Snowflake's documentation."
          examples:
          - "accountname.us-east-2.aws.snowflakecomputing.com"
          - "accountname.snowflakecomputing.com"
          type: "string"
          title: "Host"
          order: 0
        role:
          description: "The role you created for Airbyte to access Snowflake."
          examples:
          - "AIRBYTE_ROLE"
          type: "string"
          title: "Role"
          order: 1
        warehouse:
          description: "The warehouse you created for Airbyte to sync data into."
          examples:
          - "AIRBYTE_WAREHOUSE"
          type: "string"
          title: "Warehouse"
          order: 2
        database:
          description: "The database you created for Airbyte to sync data into."
          examples:
          - "AIRBYTE_DATABASE"
          type: "string"
          title: "Database"
          order: 3
        schema:
          description: "The default schema is used as the target schema for all statements\
            \ issued from the connection that do not explicitly specify a schema name..\
            \ Schema name would be transformed to allowed by Snowflake if it not follow\
            \ Snowflake Naming Conventions https://docs.airbyte.io/integrations/destinations/snowflake#notes-about-snowflake-naming-conventions "
          examples:
          - "AIRBYTE_SCHEMA"
          type: "string"
          title: "Default Schema"
          order: 4
        username:
          description: "The username you created to allow Airbyte to access the database."
          examples:
          - "AIRBYTE_USER"
          type: "string"
          title: "Username"
          order: 5
        credentials:
          title: "Authorization Method"
          type: "object"
          oneOf:
          - type: "object"
            title: "OAuth2.0"
            order: 0
            required:
            - "access_token"
            - "refresh_token"
            properties:
              auth_type:
                type: "string"
                const: "OAuth2.0"
                enum:
                - "OAuth2.0"
                default: "OAuth2.0"
                order: 0
              client_id:
                type: "string"
                title: "Client ID"
                description: "The Client ID of your Drift developer application."
                airbyte_secret: true
              client_secret:
                type: "string"
                title: "Client Secret"
                description: "The Client Secret of your Drift developer application."
                airbyte_secret: true
              access_token:
                type: "string"
                title: "Access Token"
                description: "Access Token for making authenticated requests."
                airbyte_secret: true
              refresh_token:
                type: "string"
                title: "Refresh Token"
                description: "Refresh Token for making authenticated requests."
                airbyte_secret: true
          - title: "Username and Password"
            type: "object"
            required:
            - "password"
            order: 1
            properties:
              password:
                description: "The password associated with the username."
                type: "string"
                airbyte_secret: true
                title: "Password"
                order: 1
          order: 6
        jdbc_url_params:
          description: "Additional properties to pass to the JDBC URL string when\
            \ connecting to the database formatted as 'key=value' pairs separated\
            \ by the symbol '&'. (example: key1=value1&key2=value2&key3=value3)."
          title: "JDBC URL Params"
          type: "string"
          order: 7
        loading_method:
          type: "object"
          title: "Loading Method"
          description: "The loading method used to send data to Snowflake."
          order: 8
          oneOf:
          - title: "Select another option"
            additionalProperties: false
            description: "Select another option"
            required:
            - "method"
            properties:
              method:
                type: "string"
                enum:
                - "Standard"
                default: "Standard"
          - title: "[Recommended] Internal Staging"
            additionalProperties: false
            description: "Writes large batches of records to a file, uploads the file\
              \ to Snowflake, then uses <pre>COPY INTO table</pre> to upload the file.\
              \ Recommended for large production workloads for better speed and scalability."
            required:
            - "method"
            properties:
              method:
                type: "string"
                enum:
                - "Internal Staging"
                default: "Internal Staging"
          - title: "AWS S3 Staging"
            additionalProperties: false
            description: "Writes large batches of records to a file, uploads the file\
              \ to S3, then uses <pre>COPY INTO table</pre> to upload the file. Recommended\
              \ for large production workloads for better speed and scalability."
            required:
            - "method"
            - "s3_bucket_name"
            - "access_key_id"
            - "secret_access_key"
            properties:
              method:
                type: "string"
                enum:
                - "S3 Staging"
                default: "S3 Staging"
                order: 0
              s3_bucket_name:
                title: "S3 Bucket Name"
                type: "string"
                description: "The name of the staging S3 bucket. Airbyte will write\
                  \ files to this bucket and read them via <pre>COPY</pre> statements\
                  \ on Snowflake."
                examples:
                - "airbyte.staging"
                order: 1
              s3_bucket_region:
                title: "S3 Bucket Region"
                type: "string"
                default: ""
                description: "The region of the S3 staging bucket which is used when\
                  \ utilising a copy strategy."
                enum:
                - ""
                - "us-east-1"
                - "us-east-2"
                - "us-west-1"
                - "us-west-2"
                - "af-south-1"
                - "ap-east-1"
                - "ap-south-1"
                - "ap-northeast-1"
                - "ap-northeast-2"
                - "ap-northeast-3"
                - "ap-southeast-1"
                - "ap-southeast-2"
                - "ca-central-1"
                - "cn-north-1"
                - "cn-northwest-1"
                - "eu-central-1"
                - "eu-west-1"
                - "eu-west-2"
                - "eu-west-3"
                - "eu-south-1"
                - "eu-north-1"
                - "sa-east-1"
                - "me-south-1"
                order: 2
              access_key_id:
                type: "string"
                description: "The Access Key Id granting allow one to access the above\
                  \ S3 staging bucket. Airbyte requires Read and Write permissions\
                  \ to the given bucket."
                title: "S3 Key Id"
                airbyte_secret: true
                order: 3
              secret_access_key:
                type: "string"
                description: "The corresponding secret to the above access key id."
                title: "S3 Access Key"
                airbyte_secret: true
                order: 4
              part_size:
                type: "integer"
                default: 5
                examples:
                - 5
                description: "Optional. Increase this if syncing tables larger than\
                  \ 100GB. Only relevant for COPY. Files are streamed to S3 in parts.\
                  \ This determines the size of each part, in MBs. As S3 has a limit\
                  \ of 10,000 parts per file, part size affects the table size. This\
                  \ is 10MB by default, resulting in a default limit of 100GB tables.\
                  \ Note, a larger part size will result in larger memory requirements.\
                  \ A rule of thumb is to multiply the part size by 10 to get the\
                  \ memory requirement. Modify this with care."
                title: "Stream Part Size"
                order: 5
              purge_staging_data:
                title: "Purge Staging Files and Tables"
                type: "boolean"
                description: "Whether to delete the staging files from S3 after completing\
                  \ the sync. See the docs for details. Only relevant for COPY. Defaults\
                  \ to true."
                default: true
                order: 6
          - title: "GCS Staging"
            additionalProperties: false
            description: "Writes large batches of records to a file, uploads the file\
              \ to GCS, then uses <pre>COPY INTO table</pre> to upload the file. Recommended\
              \ for large production workloads for better speed and scalability."
            required:
            - "method"
            - "project_id"
            - "bucket_name"
            - "credentials_json"
            properties:
              method:
                type: "string"
                enum:
                - "GCS Staging"
                default: "GCS Staging"
                order: 0
              project_id:
                title: "GCP Project ID"
                type: "string"
                description: "The name of the GCP project ID for your credentials."
                examples:
                - "my-project"
                order: 1
              bucket_name:
                title: "GCS Bucket Name"
                type: "string"
                description: "The name of the staging GCS bucket. Airbyte will write\
                  \ files to this bucket and read them via <pre>COPY</pre> statements\
                  \ on Snowflake."
                examples:
                - "airbyte-staging"
                order: 2
              credentials_json:
                title: "Google Application Credentials"
                type: "string"
                description: "The contents of the JSON key file that has read/write\
                  \ permissions to the staging GCS bucket. You will separately need\
                  \ to grant bucket access to your Snowflake GCP service account.\
                  \ See the <a href=\"https://cloud.google.com/iam/docs/creating-managing-service-account-keys#creating_service_account_keys\"\
                  >GCP docs</a> for more information on how to generate a JSON key\
                  \ for your service account."
                airbyte_secret: true
                multiline: true
                order: 3
          - title: "Azure Blob Storage Staging"
            additionalProperties: false
            description: "Writes large batches of records to a file, uploads the file\
              \ to Azure Blob Storage, then uses <pre>COPY INTO table</pre> to upload\
              \ the file. Recommended for large production workloads for better speed\
              \ and scalability."
            required:
            - "method"
            - "azure_blob_storage_account_name"
            - "azure_blob_storage_container_name"
            - "azure_blob_storage_sas_token"
            properties:
              method:
                type: "string"
                enum:
                - "Azure Blob Staging"
                default: "Azure Blob Staging"
                order: 0
              azure_blob_storage_endpoint_domain_name:
                title: "Endpoint Domain Name"
                type: "string"
                default: "blob.core.windows.net"
                description: "This is Azure Blob Storage endpoint domain name. Leave\
                  \ default value (or leave it empty if run container from command\
                  \ line) to use Microsoft native from example."
                examples:
                - "blob.core.windows.net"
                order: 1
              azure_blob_storage_account_name:
                title: "Azure Blob Storage Account Name"
                type: "string"
                description: "The account's name of the Azure Blob Storage."
                examples:
                - "airbyte5storage"
                order: 2
              azure_blob_storage_container_name:
                title: "Azure blob storage container (Bucket) Name"
                type: "string"
                description: "The name of the Azure blob storage container. *This\
                  \ needs to coincide with the container specified in the Snowflake\
                  \ Storage Integration and Snowflake Azure External Stage (see description\
                  \ of 'Snowflake Azure External Stage' for details"
                examples:
                - "airbytetestcontainername"
                order: 3
              azure_blob_storage_sas_token:
                title: "SAS Token"
                type: "string"
                airbyte_secret: true
                description: "Shared access signature(SAS) token to grant Snowflake\
                  \ limited access to objects in your storage account. See more https://docs.snowflake.com/en/user-guide/data-load-azure-config.html#option-2-generating-a-sas-token"
                examples:
                - "?sv=2016-05-31&ss=b&srt=sco&sp=rwdl&se=2018-06-27T10:05:50Z&st=2017-06-27T02:05:50Z&spr=https,http&sig=bgqQwoXwxzuD2GJfagRg7VOS8hzNr3QLT7rhS8OFRLQ%3D"
                order: 4
    supportsIncremental: true
    supportsNormalization: true
    supportsDBT: true
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
    - "append_dedup"
    advanced_auth:
      auth_flow_type: "oauth2.0"
      predicate_key:
      - "credentials"
      - "auth_type"
      predicate_value: "OAuth2.0"
      oauth_config_specification:
        oauth_user_input_from_connector_config_specification:
          type: "object"
          properties:
            host:
              type: "string"
              path_in_connector_config:
              - "host"
        complete_oauth_output_specification:
          type: "object"
          additionalProperties: false
          properties:
            access_token:
              type: "string"
              path_in_connector_config:
              - "credentials"
              - "access_token"
            refresh_token:
              type: "string"
              path_in_connector_config:
              - "credentials"
              - "refresh_token"
        complete_oauth_server_input_specification:
          type: "object"
          additionalProperties: false
          properties:
            client_id:
              type: "string"
            client_secret:
              type: "string"
        complete_oauth_server_output_specification:
          type: "object"
          additionalProperties: false
          properties:
            client_id:
              type: "string"
              path_in_connector_config:
              - "credentials"
              - "client_id"
            client_secret:
              type: "string"
              path_in_connector_config:
              - "credentials"
              - "client_secret"
- dockerImage: "airbyte/destination-mariadb-columnstore:0.1.4"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/mariadb-columnstore"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "MariaDB Columnstore Destination Spec"
      type: "object"
      required:
      - "host"
      - "port"
      - "username"
      - "database"
      additionalProperties: true
      properties:
        host:
          title: "Host"
          description: "The Hostname of the database."
          type: "string"
          order: 0
        port:
          title: "Port"
          description: "The Port of the database."
          type: "integer"
          minimum: 0
          maximum: 65536
          default: 3306
          examples:
          - "3306"
          order: 1
        database:
          title: "Database"
          description: "Name of the database."
          type: "string"
          order: 2
        username:
          title: "Username"
          description: "The Username which is used to access the database."
          type: "string"
          order: 3
        password:
          title: "Password"
          description: "The Password associated with the username."
          type: "string"
          airbyte_secret: true
          order: 4
        tunnel_method:
          type: "object"
          title: "SSH Tunnel Method"
          description: "Whether to initiate an SSH tunnel before connecting to the\
            \ database, and if so, which kind of authentication to use."
          oneOf:
          - title: "No Tunnel"
            required:
            - "tunnel_method"
            properties:
              tunnel_method:
                description: "No ssh tunnel needed to connect to database"
                type: "string"
                const: "NO_TUNNEL"
                order: 0
          - title: "SSH Key Authentication"
            required:
            - "tunnel_method"
            - "tunnel_host"
            - "tunnel_port"
            - "tunnel_user"
            - "ssh_key"
            properties:
              tunnel_method:
                description: "Connect through a jump server tunnel host using username\
                  \ and ssh key"
                type: "string"
                const: "SSH_KEY_AUTH"
                order: 0
              tunnel_host:
                title: "SSH Tunnel Jump Server Host"
                description: "Hostname of the jump server host that allows inbound\
                  \ ssh tunnel."
                type: "string"
                order: 1
              tunnel_port:
                title: "SSH Connection Port"
                description: "Port on the proxy/jump server that accepts inbound ssh\
                  \ connections."
                type: "integer"
                minimum: 0
                maximum: 65536
                default: 22
                examples:
                - "22"
                order: 2
              tunnel_user:
                title: "SSH Login Username"
                description: "OS-level username for logging into the jump server host."
                type: "string"
                order: 3
              ssh_key:
                title: "SSH Private Key"
                description: "OS-level user account ssh key credentials in RSA PEM\
                  \ format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )"
                type: "string"
                airbyte_secret: true
                multiline: true
                order: 4
          - title: "Password Authentication"
            required:
            - "tunnel_method"
            - "tunnel_host"
            - "tunnel_port"
            - "tunnel_user"
            - "tunnel_user_password"
            properties:
              tunnel_method:
                description: "Connect through a jump server tunnel host using username\
                  \ and password authentication"
                type: "string"
                const: "SSH_PASSWORD_AUTH"
                order: 0
              tunnel_host:
                title: "SSH Tunnel Jump Server Host"
                description: "Hostname of the jump server host that allows inbound\
                  \ ssh tunnel."
                type: "string"
                order: 1
              tunnel_port:
                title: "SSH Connection Port"
                description: "Port on the proxy/jump server that accepts inbound ssh\
                  \ connections."
                type: "integer"
                minimum: 0
                maximum: 65536
                default: 22
                examples:
                - "22"
                order: 2
              tunnel_user:
                title: "SSH Login Username"
                description: "OS-level username for logging into the jump server host"
                type: "string"
                order: 3
              tunnel_user_password:
                title: "Password"
                description: "OS-level password for logging into the jump server host"
                type: "string"
                airbyte_secret: true
                order: 4
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
- dockerImage: "ghcr.io/devmate-cloud/streamr-airbyte-connectors:0.0.1"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/streamr"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Destination Streamr"
      type: "object"
      required:
      - "privateKey"
      - "streamId"
      additionalProperties: false
      properties:
        privateKey:
          type: "string"
          description: "You private key on Streamr"
          airbyte_secret: true
        streamId:
          type: "string"
          description: "Your full Stream ID"
          examples:
          - "0x0d0102474519cd2fc1b3e3f962a87e39cbcbead2/test-streamr"
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "append"
    - "append_dedup"
- dockerImage: "airbyte/destination-scylla:0.1.1"
  spec:
    documentationUrl: "https://docs.airbyte.io/integrations/destinations/scylla"
    connectionSpecification:
      $schema: "http://json-schema.org/draft-07/schema#"
      title: "Scylla Destination Spec"
      type: "object"
      required:
      - "keyspace"
      - "username"
      - "password"
      - "address"
      - "port"
      additionalProperties: true
      properties:
        keyspace:
          title: "Keyspace"
          description: "Default Scylla keyspace to create data in."
          type: "string"
          order: 0
        username:
          title: "Username"
          description: "Username to use to access Scylla."
          type: "string"
          order: 1
        password:
          title: "Password"
          description: "Password associated with Scylla."
          type: "string"
          airbyte_secret: true
          order: 2
        address:
          title: "Address"
          description: "Address to connect to."
          type: "string"
          order: 3
        port:
          title: "Port"
          description: "Port of Scylla."
          type: "integer"
          minimum: 0
          maximum: 65536
          default: 9042
          order: 4
        replication:
          title: "Replication factor"
          type: "integer"
          description: "Indicates to how many nodes the data should be replicated\
            \ to."
          default: 1
          order: 5
    supportsIncremental: true
    supportsNormalization: false
    supportsDBT: false
    supported_destination_sync_modes:
    - "overwrite"
    - "append"
