VERSION=0.27.1-alpha

# Airbyte Internal Job Database, see https://docs.airbyte.io/operator-guides/configuring-airbyte-db
DATABASE_USER=docker
DATABASE_PASSWORD=docker
DATABASE_HOST=db
DATABASE_PORT=5432
DATABASE_DB=airbyte
# translate manually DATABASE_URL=jdbc:postgresql://${DATABASE_HOST}:${DATABASE_PORT/${DATABASE_DB}
DATABASE_URL=jdbc:postgresql://db:5432/airbyte

# Set to 1 to use a database for config persistence, see https://docs.airbyte.io/operator-guides/configuring-airbyte-db
USE_CONFIG_DATABASE=1

# By default, the Config Database is the same as the Job Database.
# Uncomment the following variable if a different Config Database is needed.
# CONFIG_DATABASE_USER=docker
# CONFIG_DATABASE_PASSWORD=docker
# CONFIG_DATABASE_HOST=db
# CONFIG_DATABASE_PORT=5432
# CONFIG_DATABASE_DB=airbyte_config
# CONFIG_DATABASE_URL=jdbc:postgresql://db:5432/airbyte_config

# When using the airbyte-db via default docker image:
CONFIG_ROOT=/data
DATA_DOCKER_MOUNT=airbyte_data
DB_DOCKER_MOUNT=airbyte_db

# Temporal.io worker configuration
TEMPORAL_HOST=airbyte-temporal:7233

# Workspace storage for running jobs (logs, etc)
WORKSPACE_ROOT=/tmp/workspace
WORKSPACE_DOCKER_MOUNT=airbyte_workspace

# Local mount to access local files from filesystem
# todo (cgardens) - when we are mount raw directories instead of named volumes, *_DOCKER_MOUNT must
# be the same as *_ROOT.
# Issue: https://github.com/airbytehq/airbyte/issues/578
LOCAL_ROOT=/tmp/airbyte_local
LOCAL_DOCKER_MOUNT=/tmp/airbyte_local
# todo (cgardens) - hack to handle behavior change in docker compose. *_PARENT directories MUST
# already exist on the host filesystem and MUST be parents of *_ROOT.
# Issue: https://github.com/airbytehq/airbyte/issues/577
HACK_LOCAL_ROOT_PARENT=/tmp

# Miscellaneous
TRACKING_STRATEGY=segment
WEBAPP_URL=http://localhost:8000/
API_URL=/api/v1/
INTERNAL_API_HOST=airbyte-server:8001
LOG_LEVEL=INFO

# Cloud log backups. Don't use this unless you know what you're doing. Mainly for Airbyte devs.
# If you just want to capture Docker logs, you probably want to use something like this instead:
# https://docs.docker.com/config/containers/logging/configure/
S3_LOG_BUCKET=
S3_LOG_BUCKET_REGION=
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
S3_MINIO_ENDPOINT=
S3_PATH_STYLE_ACCESS=

GCP_STORAGE_BUCKET=

# Docker Resource Limits
RESOURCE_CPU_REQUEST=
RESOURCE_CPU_LIMIT=
RESOURCE_MEMORY_REQUEST=
RESOURCE_MEMORY_LIMIT=
