<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="INFO">
    <Properties>

        <!-- The following patterns mask the string apikey=<string> to apikey=***** to prevent secrets leaking. -->
        <Property name="default-pattern">%d{yyyy-MM-dd HH:mm:ss}{GMT+0} %highlight{%p} %C{1.}(%M):%L - %X - %replace{%m}{apikey=\w*}{apikey=*****}%n</Property>
        <Property name="docker-worker-file-pattern">%d{yyyy-MM-dd HH:mm:ss}{GMT+0} %p (%X{job_root}) %C{1}(%M):%L - %replace{%m}{apikey=\w*}{apikey=*****}%n</Property>
        <!-- Remove paths from logs on Cloud as users aren't able to access file paths and these end up being noise. -->
        <Property name="cloud-worker-file-pattern">%d{yyyy-MM-dd HH:mm:ss} %-5p %replace{%m}{apikey=\w*}{apikey=*****}%n</Property>

        <!-- Always log INFO by default. -->
        <Property name="log-level">$${env:LOG_LEVEL:-INFO}</Property>

        <Property name="s3-bucket">$${env:S3_LOG_BUCKET}</Property>
        <Property name="s3-region">$${env:S3_LOG_BUCKET_REGION}</Property>
        <Property name="s3-aws-key">$${env:AWS_ACCESS_KEY_ID}</Property>
        <Property name="s3-aws-secret">$${env:AWS_SECRET_ACCESS_KEY}</Property>
        <Property name="s3-minio-endpoint">$${env:S3_MINIO_ENDPOINT}</Property>
        <Property name="s3-path-style-access">$${env:S3_PATH_STYLE_ACCESS}</Property>

        <Property name="gcp-storage-bucket">$${env:GCP_STORAGE_BUCKET}</Property>
    </Properties>

    <Appenders>
        <Console name="Default" target="SYSTEM_OUT">
            <PatternLayout pattern="${default-pattern}"/>
        </Console>

        <Routing name="LogSplit">
            <Routes pattern="$${ctx:job_log_path}">
                <!-- Don't split logs if job_root isn't defined -->
                <Route key="$${ctx:job_log_path}">
                    <Null name="/dev/null"/>
                </Route>
                <Route>
                    <File name="${ctx:job_log_path}-local" fileName="${ctx:job_log_path}">
                        <PatternLayout pattern="${docker-worker-file-pattern}"/>
                    </File>
                </Route>
            </Routes>
            <IdlePurgePolicy timeToLive="15" timeUnit="minutes"/>
        </Routing>

        <!--
            Separate routers are created for each cloud logger as
            1) a Route only accepts 1 appender
            2) Routes don't support routing log output to more than Route
        -->
        <Routing name="LogSplitCloud">
            <Routes pattern="$${ctx:job_log_path}">
                <!-- Don't split logs if job_root isn't defined -->
                <Route key="$${ctx:job_log_path}">
                    <Null name="/dev/null"/>
                </Route>
                <Route>
                    <Log4j2Appender name="${ctx:job_log_path}-cloud"
                      verbose="true"
                      stagingBufferAge="1"
                      s3Bucket="${s3-bucket}" s3Path="job-logging${ctx:job_log_path}" s3Region="${s3-region}"
                      s3AwsKey="${s3-aws-key}" s3AwsSecret="${s3-aws-secret}"
                      s3ServiceEndpoint="${s3-minio-endpoint}" s3PathStyleAccess="${s3-path-style-access}"
                      gcpStorageBucket="${gcp-storage-bucket}" gcpStorageBlobNamePrefix="job-logging${ctx:job_log_path}">
                        <PatternLayout pattern="${cloud-worker-file-pattern}"/>
                    </Log4j2Appender>
                </Route>
            </Routes>
            <IdlePurgePolicy timeToLive="15" timeUnit="minutes"/>
        </Routing>

        <Routing name="AppLogSplit">
            <Routes pattern="$${ctx:workspace_app_root}">
                <!-- Don't split logs if workspace_app_log_root isn't defined -->
                <Route key="$${ctx:workspace_app_root}">
                    <Null name="/dev/null"/>
                </Route>
                <Route>
                    <RollingFile
                            name="${ctx:workspace_app_root}-local"
                            fileName="${ctx:workspace_app_root}/logs.log"
                            filePattern="${ctx:workspace_app_root}/logs.%i.log.gz"
                            ignoreExceptions="false">
                        <PatternLayout pattern="${docker-worker-file-pattern}"/>
                        <Policies>
                            <SizeBasedTriggeringPolicy size="100MB" />
                        </Policies>
                        <DefaultRolloverStrategy max="3" />
                    </RollingFile>
                </Route>
            </Routes>
            <IdlePurgePolicy timeToLive="15" timeUnit="minutes"/>
        </Routing>
        <Routing name="AppLogSplitCloud">
            <Routes pattern="$${ctx:workspace_app_root}">
                <!-- Don't split logs if workspace_app_log_root isn't defined -->
                <Route key="$${ctx:workspace_app_root}">
                    <Null name="/dev/null"/>
                </Route>
                <Route>
                    <Log4j2Appender name="app-logging/${ctx:workspace_app_root}-cloud/"
                      stagingBufferAge="1"
                      s3Bucket="${s3-bucket}" s3Path="app-logging${ctx:workspace_app_root}" s3Region="${s3-region}"
                      s3AwsKey="${s3-aws-key}" s3AwsSecret="${s3-aws-secret}"
                      s3ServiceEndpoint="${s3-minio-endpoint}" s3PathStyleAccess="${s3-path-style-access}"
                      gcpStorageBucket="${gcp-storage-bucket}" gcpStorageBlobNamePrefix="app-logging${ctx:workspace_app_root}">
                        <PatternLayout pattern="${cloud-worker-file-pattern}"/>
                    </Log4j2Appender>
                </Route>
            </Routes>
            <IdlePurgePolicy timeToLive="15" timeUnit="minutes"/>
        </Routing>
    </Appenders>

    <Loggers>
        <Root level="${log-level}">
            <AppenderRef ref="Default"/>
            <AppenderRef ref="LogSplit"/>
            <AppenderRef ref="LogSplitCloud"/>
            <AppenderRef ref="AppLogSplit"/>
            <AppenderRef ref="AppLogSplitCloud"/>
        </Root>

        <Logger name="org.eclipse.jetty" level="INFO" />
        <Logger name="com.github.dockerjava" level="INFO" />
        <Logger name="org.apache.hc" level="INFO" />
        <Logger name="org.jooq" level="INFO" />
        <logger name="org.jooq.Constants" level="OFF" />
        <Logger name="com.networknt.schema" level="INFO" />
        <Logger name="me.andrz.jackson" level="INFO" />
        <Logger name="com.leansoft.bigqueue" level="INFO" />
        <Logger name="io.netty" level="INFO" />
        <Logger name="io.grpc" level="INFO" />
        <Logger name="io.temporal" level="INFO" />
        <Logger name="org.apache" level="WARN" />
        <Logger name="httpclient" level="WARN" />
        <Logger name="com.amazonaws" level="WARN" />
        <!--MySQL Debezium connector generates a log whenever it converts an invalid value to empty value.
        Ex: Invalid value '0000-00-00 00:00:00' stored in column 'column_name' of table 'table_name' converted to empty value
        If a database has tons of such values, the logs would be filled with such messages-->
        <Logger name="io.debezium.connector.mysql.MySqlValueConverters" level="OFF" />
        <!--MySQL Debezium connector generates a log whenever it comes across a DDL query to mention that it skipped it.
        If a database has tons of DDL queries, the logs would be filled with such messages-->
        <Logger name="io.debezium.relational.history" level="OFF" />

    </Loggers>

</Configuration>
