// #############################################################################################
// #                                                                                           #
// #    _______________ _____  ______      _                  _     _                          #
// #   |_  |  _  | ___ /  __ \ |  _  \    (_)                | |   (_)                         #
// #     | | | | | |_/ | /  \/ | | | |_ __ ___   _____ _ __  | |    _  ___ ___ _ __  ___  ___  #
// #     | | | | | ___ | |     | | | | '__| \ \ / / _ | '__| | |   | |/ __/ _ | '_ \/ __|/ _ \ #
// # /\__/ | |/ /| |_/ | \__/\ | |/ /| |  | |\ V |  __| |    | |___| | (_|  __| | | \__ |  __/ #
// # \____/|___/ \____/ \____/ |___/ |_|  |_| \_/ \___|_|    \_____|_|\___\___|_| |_|___/\___| #
// #                                                                                           #
// #           By building this connector, you agree to the JDBC ODBC driver license:          #
// #                  https://databricks.com/jdbc-odbc-driver-license                          #
// #                                                                                           #
// #############################################################################################

plugins {
    id 'application'
    id 'airbyte-docker'
    id 'airbyte-integration-test-java'
    id "de.undercouch.download" version "5.0.1"
}

application {
    mainClass = 'io.airbyte.integrations.destination.databricks.DatabricksDestination'
}

dependencies {
    implementation project(':airbyte-db:lib')
    implementation project(':airbyte-config:models')
    implementation project(':airbyte-protocol:models')
    implementation project(':airbyte-integrations:bases:base-java')
    implementation files(project(':airbyte-integrations:bases:base-java').airbyteDocker.outputs)
    implementation project(':airbyte-integrations:connectors:destination-jdbc')
    implementation project(':airbyte-integrations:connectors:destination-s3')
    // Spark JDBC is not checked into the repo for legal reason
    implementation files("lib/SparkJDBC42.jar")

    // parquet
    implementation group: 'org.apache.hadoop', name: 'hadoop-common', version: '3.3.0'
    implementation group: 'org.apache.hadoop', name: 'hadoop-aws', version: '3.3.0'
    implementation group: 'org.apache.hadoop', name: 'hadoop-mapreduce-client-core', version: '3.3.0'
    implementation group: 'org.apache.parquet', name: 'parquet-avro', version: '1.12.0'
    implementation('tech.allegro.schema.json2avro:converter') {
        version {
            branch = 'master'
        }
    }

    integrationTestJavaImplementation project(':airbyte-integrations:bases:standard-destination-test')
    integrationTestJavaImplementation project(':airbyte-integrations:connectors:destination-databricks')
}

task downloadJdbcDriverZip(type: Download) {
    src 'https://databricks-bi-artifacts.s3.us-east-2.amazonaws.com/simbaspark-drivers/jdbc/2.6.21/SimbaSparkJDBC42-2.6.21.1039.zip'
    dest new File(buildDir, 'SimbaSparkJDBC42-2.6.21.1039.zip')
    overwrite false
}

task extractJdbcDriverFile(dependsOn: downloadJdbcDriverZip, type: Copy) {
    from {
        zipTree(downloadJdbcDriverZip.dest)
    }
    into 'lib/'
    include 'SparkJDBC42.jar'
}

compileJava.dependsOn tasks.extractJdbcDriverFile
