import groovy.json.JsonOutput
import groovy.json.JsonSlurper

plugins {
    id 'application'
    id 'airbyte-java-connector'
    id 'org.jsonschema2dataclass' version "6.0.0"
}

airbyteJavaConnector {
    cdkVersionRequired = '0.4.5'
    features = ['db-destinations', 's3-destinations']
    useLocalCdk = false
}

airbyteJavaConnector.addCdkDependencies()

application {
    mainClass = 'io.airbyte.integrations.destination.bigquery.BigQueryDestination'
    applicationDefaultJvmArgs = ['-XX:+ExitOnOutOfMemoryError', '-XX:MaxRAMPercentage=75.0',
                                 '-XX:NativeMemoryTracking=detail', '-XX:+UnlockDiagnosticVMOptions',
                                 '-XX:GCLockerRetryAllocationCount=100',
//            '-Djava.rmi.server.hostname=localhost',
//            '-Dcom.sun.management.jmxremote=true',
//            '-Dcom.sun.management.jmxremote.port=6000',
//            '-Dcom.sun.management.jmxremote.rmi.port=6000',
//            '-Dcom.sun.management.jmxremote.local.only=false',
//            '-Dcom.sun.management.jmxremote.authenticate=false',
//            '-Dcom.sun.management.jmxremote.ssl=false'
    ]
}

airbyteJavaConnector.addCdkDependencies()

dependencies {
    implementation project(':airbyte-integrations:connectors:destination-gcs')

    implementation 'com.google.cloud:google-cloud-bigquery:2.31.1'
    implementation 'org.apache.commons:commons-lang3:3.11'
    implementation 'org.apache.commons:commons-csv:1.4'
    implementation 'org.apache.commons:commons-text:1.10.0'

    implementation group: 'com.google.cloud', name: 'google-cloud-storage', version: '2.4.5'
    implementation group: 'com.codepoetics', name: 'protonpack', version: '1.13'

    implementation (libs.airbyte.protocol) {
        exclude group: 'io.airbyte', module: 'airbyte-commons'
    }
    // implementation ('com.github.airbytehq:json-avro-converter:1.1.0') { exclude group: 'ch.qos.logback', module: 'logback-classic'}

    integrationTestJavaImplementation project(':airbyte-integrations:connectors:destination-bigquery')

    // TODO: declare typing-deduping as a CDK feature instead of importing from source.
    implementation project(':airbyte-cdk:java:airbyte-cdk:typing-deduping')
    integrationTestJavaImplementation testFixtures(project(':airbyte-cdk:java:airbyte-cdk:typing-deduping'))

    // TODO: remove these dependencies (what's S3 doing here???)
    implementation libs.aws.java.sdk.s3
    implementation libs.s3
}

def connectionSpecificationSchemaFile = file(
        "${buildDir}/generated/sources/connectionSpecification/${project.name}-connection-config.json")

tasks.register('extractConnectionSpecificationSchema') {

    def inputFile = file("${projectDir}/src/main/resources/spec.json")
    inputs.file inputFile

    def outputFile = connectionSpecificationSchemaFile
    outputs.file outputFile

    doFirst {
        // Read the input JSON file
        def inputJson = new JsonSlurper().parseText(inputFile.text)
        logger.info "Parsed JSON from input: ${inputFile}"
        def properties = inputJson["connectionSpecification"]["properties"]
        // underlying jsonschema2pojo library cannot generate ambigious oneOf classes.
        // alter the oneOf property to pull the common required fields to top level (should always be one in spec case)
        // and add it as a property, let others be additionalProperties to use JsonNode functions
        def additionalPropertiesType = [type: 'object', existingJavaType: 'com.fasterxml.jackson.databind.JsonNode']
        properties.each { property ->
            if (property.value.type == "object" && property.value.oneOf != null) {
                def requiredFieldsList = property.value.oneOf.collect {it.required}
                def commonRequiredFields = requiredFieldsList.inject {acc, list -> acc.intersect(list)}
                commonRequiredFields.each {fieldname ->
                    def requiredObjectFromOneOf = property.value.oneOf.first()['properties'][fieldname as String]
                    property.value.properties = [(fieldname):requiredObjectFromOneOf]
                    property.value.additionalProperties = additionalPropertiesType

                }
                property.value.remove('oneOf')
            }
        }
        inputJson["connectionSpecification"].additionalProperties = additionalPropertiesType
        // Get schema part
        // def transformedJson = inputJson["connectionSpecification"]
        def connectionSpec = inputJson["connectionSpecification"]

        // Convert the transformed JSON back to a string
        def transformedJsonString = JsonOutput.toJson(connectionSpec)

        // Write the transformed JSON string to the output file in the build directory
        outputFile.write(transformedJsonString)

        // Print a message indicating the transformation is done
        logger.info "Transformed JSON written to: ${outputFile}"
    }
}

//tasks.generateJsonSchema2DataClass.dependsOn("extractConnectionSpecificationSchema")

// https://github.com/jsonschema2dataclass/js2d-gradle/blob/main/docs/usage/parameters_6.adoc
jsonSchema2Pojo {
    executions{
        main {
            io.delimitersPropertyWord = '_'
            io.source.setFrom connectionSpecificationSchemaFile
            klass.annotateGenerated = false
            klass.targetPackage = 'io.airbyte.integrations.destination.bigquery'
            //methods.builders = true
            //methods.buildersInnerClass= true
        }
    }
}
tasks.named('generateJsonSchema2DataClassConfigMain').configure {
    dependsOn tasks.named('extractConnectionSpecificationSchema')
}
tasks.register('generate').configure {
    dependsOn tasks.named('generateJsonSchema2DataClass')
}

configurations.all {
  resolutionStrategy {
    // at time of writing: deps.toml declares google-cloud-storage 2.17.2
    // which pulls in google-api-client:2.2.0
    // which conflicts with google-cloud-bigquery, which requires google-api-client:1.x
    // google-cloud-storage is OK with downgrading to anything >=1.31.1.
    force 'com.google.api-client:google-api-client:1.31.5'
  }
}
