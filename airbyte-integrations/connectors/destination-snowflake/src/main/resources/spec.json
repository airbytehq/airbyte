{
  "documentationUrl": "https://docs.airbyte.io/integrations/destinations/snowflake",
  "supportsIncremental": true,
  "supportsNormalization": true,
  "supportsDBT": true,
  "supported_destination_sync_modes": ["overwrite", "append", "append_dedup"],
  "connectionSpecification": {
    "$schema": "http://json-schema.org/draft-07/schema#",
    "title": "Snowflake Destination Spec",
    "type": "object",
    "required": ["host", "role", "warehouse", "database", "schema", "username"],
    "additionalProperties": true,
    "properties": {
      "host": {
        "description": "The host domain of the snowflake instance (must include the account, region, cloud environment, and end with snowflakecomputing.com). The account identifier differs depending on your cloud region, be sure to verify with Snowflake's documentation.",
        "examples": [
          "accountname.us-east-2.aws.snowflakecomputing.com",
          "accountname.snowflakecomputing.com"
        ],
        "type": "string",
        "title": "Host",
        "order": 0
      },
      "role": {
        "description": "The role you created for Airbyte to access Snowflake.",
        "examples": ["AIRBYTE_ROLE"],
        "type": "string",
        "title": "Role",
        "order": 1
      },
      "warehouse": {
        "description": "The warehouse you created for Airbyte to sync data into.",
        "examples": ["AIRBYTE_WAREHOUSE"],
        "type": "string",
        "title": "Warehouse",
        "order": 2
      },
      "database": {
        "description": "The database you created for Airbyte to sync data into.",
        "examples": ["AIRBYTE_DATABASE"],
        "type": "string",
        "title": "Database",
        "order": 3
      },
      "schema": {
        "description": "The default schema is used as the target schema for all statements issued from the connection that do not explicitly specify a schema name.. Schema name would be transformed to allowed by Snowflake if it not follow Snowflake Naming Conventions https://docs.airbyte.io/integrations/destinations/snowflake#notes-about-snowflake-naming-conventions ",
        "examples": ["AIRBYTE_SCHEMA"],
        "type": "string",
        "title": "Default Schema",
        "order": 4
      },
      "username": {
        "description": "The username you created to allow Airbyte to access the database.",
        "examples": ["AIRBYTE_USER"],
        "type": "string",
        "title": "Username",
        "order": 5
      },
      "credentials": {
        "title": "Authorization Method",
        "type": "object",
        "oneOf": [
          {
            "type": "object",
            "title": "OAuth2.0",
            "order": 0,
            "required": ["access_token", "refresh_token"],
            "properties": {
              "auth_type": {
                "type": "string",
                "const": "OAuth2.0",
                "enum": ["OAuth2.0"],
                "default": "OAuth2.0",
                "order": 0
              },
              "client_id": {
                "type": "string",
                "title": "Client ID",
                "description": "The Client ID of your Drift developer application.",
                "airbyte_secret": true
              },
              "client_secret": {
                "type": "string",
                "title": "Client Secret",
                "description": "The Client Secret of your Drift developer application.",
                "airbyte_secret": true
              },
              "access_token": {
                "type": "string",
                "title": "Access Token",
                "description": "Access Token for making authenticated requests.",
                "airbyte_secret": true
              },
              "refresh_token": {
                "type": "string",
                "title": "Refresh Token",
                "description": "Refresh Token for making authenticated requests.",
                "airbyte_secret": true
              }
            }
          },
          {
            "title": "Username and Password",
            "type": "object",
            "required": ["password"],
            "order": 1,
            "properties": {
              "password": {
                "description": "The password associated with the username.",
                "type": "string",
                "airbyte_secret": true,
                "title": "Password",
                "order": 1
              }
            }
          }
        ],
        "order": 6
      },
      "jdbc_url_params": {
        "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as 'key=value' pairs separated by the symbol '&'. (example: key1=value1&key2=value2&key3=value3).",
        "title": "JDBC URL Params",
        "type": "string",
        "order": 7
      },
      "loading_method": {
        "type": "object",
        "title": "Loading Method",
        "description": "The loading method used to send data to Snowflake.",
        "order": 8,
        "oneOf": [
          {
            "title": "Select another option",
            "additionalProperties": false,
            "description": "Select another option",
            "required": ["method"],
            "properties": {
              "method": {
                "type": "string",
                "enum": ["Standard"],
                "default": "Standard"
              }
            }
          },
          {
            "title": "[Recommended] Internal Staging",
            "additionalProperties": false,
            "description": "Writes large batches of records to a file, uploads the file to Snowflake, then uses <pre>COPY INTO table</pre> to upload the file. Recommended for large production workloads for better speed and scalability.",
            "required": ["method"],
            "properties": {
              "method": {
                "type": "string",
                "enum": ["Internal Staging"],
                "default": "Internal Staging"
              }
            }
          },
          {
            "title": "AWS S3 Staging",
            "additionalProperties": false,
            "description": "Writes large batches of records to a file, uploads the file to S3, then uses <pre>COPY INTO table</pre> to upload the file. Recommended for large production workloads for better speed and scalability.",
            "required": [
              "method",
              "s3_bucket_name",
              "access_key_id",
              "secret_access_key"
            ],
            "properties": {
              "method": {
                "type": "string",
                "enum": ["S3 Staging"],
                "default": "S3 Staging",
                "order": 0
              },
              "s3_bucket_name": {
                "title": "S3 Bucket Name",
                "type": "string",
                "description": "The name of the staging S3 bucket. Airbyte will write files to this bucket and read them via <pre>COPY</pre> statements on Snowflake.",
                "examples": ["airbyte.staging"],
                "order": 1
              },
              "s3_bucket_region": {
                "title": "S3 Bucket Region",
                "type": "string",
                "default": "",
                "description": "The region of the S3 staging bucket which is used when utilising a copy strategy.",
                "enum": [
                  "",
                  "us-east-1",
                  "us-east-2",
                  "us-west-1",
                  "us-west-2",
                  "af-south-1",
                  "ap-east-1",
                  "ap-south-1",
                  "ap-northeast-1",
                  "ap-northeast-2",
                  "ap-northeast-3",
                  "ap-southeast-1",
                  "ap-southeast-2",
                  "ca-central-1",
                  "cn-north-1",
                  "cn-northwest-1",
                  "eu-central-1",
                  "eu-west-1",
                  "eu-west-2",
                  "eu-west-3",
                  "eu-south-1",
                  "eu-north-1",
                  "sa-east-1",
                  "me-south-1"
                ],
                "order": 2
              },
              "access_key_id": {
                "type": "string",
                "description": "The Access Key Id granting allow one to access the above S3 staging bucket. Airbyte requires Read and Write permissions to the given bucket.",
                "title": "S3 Key Id",
                "airbyte_secret": true,
                "order": 3
              },
              "secret_access_key": {
                "type": "string",
                "description": "The corresponding secret to the above access key id.",
                "title": "S3 Access Key",
                "airbyte_secret": true,
                "order": 4
              },
              "part_size": {
                "type": "integer",
                "default": 5,
                "examples": [5],
                "description": "Optional. Increase this if syncing tables larger than 100GB. Only relevant for COPY. Files are streamed to S3 in parts. This determines the size of each part, in MBs. As S3 has a limit of 10,000 parts per file, part size affects the table size. This is 10MB by default, resulting in a default limit of 100GB tables. Note, a larger part size will result in larger memory requirements. A rule of thumb is to multiply the part size by 10 to get the memory requirement. Modify this with care.",
                "title": "Stream Part Size",
                "order": 5
              },
              "purge_staging_data": {
                "title": "Purge Staging Files and Tables",
                "type": "boolean",
                "description": "Whether to delete the staging files from S3 after completing the sync. See the docs for details. Only relevant for COPY. Defaults to true.",
                "default": true,
                "order": 6
              }
            }
          },
          {
            "title": "GCS Staging",
            "additionalProperties": false,
            "description": "Writes large batches of records to a file, uploads the file to GCS, then uses <pre>COPY INTO table</pre> to upload the file. Recommended for large production workloads for better speed and scalability.",
            "required": [
              "method",
              "project_id",
              "bucket_name",
              "credentials_json"
            ],
            "properties": {
              "method": {
                "type": "string",
                "enum": ["GCS Staging"],
                "default": "GCS Staging",
                "order": 0
              },
              "project_id": {
                "title": "GCP Project ID",
                "type": "string",
                "description": "The name of the GCP project ID for your credentials.",
                "examples": ["my-project"],
                "order": 1
              },
              "bucket_name": {
                "title": "GCS Bucket Name",
                "type": "string",
                "description": "The name of the staging GCS bucket. Airbyte will write files to this bucket and read them via <pre>COPY</pre> statements on Snowflake.",
                "examples": ["airbyte-staging"],
                "order": 2
              },
              "credentials_json": {
                "title": "Google Application Credentials",
                "type": "string",
                "description": "The contents of the JSON key file that has read/write permissions to the staging GCS bucket. You will separately need to grant bucket access to your Snowflake GCP service account. See the <a href=\"https://cloud.google.com/iam/docs/creating-managing-service-account-keys#creating_service_account_keys\">GCP docs</a> for more information on how to generate a JSON key for your service account.",
                "airbyte_secret": true,
                "multiline": true,
                "order": 3
              }
            }
          },
          {
            "title": "Azure Blob Storage Staging",
            "additionalProperties": false,
            "description": "Writes large batches of records to a file, uploads the file to Azure Blob Storage, then uses <pre>COPY INTO table</pre> to upload the file. Recommended for large production workloads for better speed and scalability.",
            "required": [
              "method",
              "azure_blob_storage_account_name",
              "azure_blob_storage_container_name",
              "azure_blob_storage_sas_token"
            ],
            "properties": {
              "method": {
                "type": "string",
                "enum": ["Azure Blob Staging"],
                "default": "Azure Blob Staging",
                "order": 0
              },
              "azure_blob_storage_endpoint_domain_name": {
                "title": "Endpoint Domain Name",
                "type": "string",
                "default": "blob.core.windows.net",
                "description": "This is Azure Blob Storage endpoint domain name. Leave default value (or leave it empty if run container from command line) to use Microsoft native from example.",
                "examples": ["blob.core.windows.net"],
                "order": 1
              },
              "azure_blob_storage_account_name": {
                "title": "Azure Blob Storage Account Name",
                "type": "string",
                "description": "The account's name of the Azure Blob Storage.",
                "examples": ["airbyte5storage"],
                "order": 2
              },
              "azure_blob_storage_container_name": {
                "title": "Azure blob storage container (Bucket) Name",
                "type": "string",
                "description": "The name of the Azure blob storage container. *This needs to coincide with the container specified in the Snowflake Storage Integration and Snowflake Azure External Stage (see description of 'Snowflake Azure External Stage' for details",
                "examples": ["airbytetestcontainername"],
                "order": 3
              },
              "azure_blob_storage_sas_token": {
                "title": "SAS Token",
                "type": "string",
                "airbyte_secret": true,
                "description": "Shared access signature(SAS) token to grant Snowflake limited access to objects in your storage account. See more https://docs.snowflake.com/en/user-guide/data-load-azure-config.html#option-2-generating-a-sas-token",
                "examples": [
                  "?sv=2016-05-31&ss=b&srt=sco&sp=rwdl&se=2018-06-27T10:05:50Z&st=2017-06-27T02:05:50Z&spr=https,http&sig=bgqQwoXwxzuD2GJfagRg7VOS8hzNr3QLT7rhS8OFRLQ%3D"
                ],
                "order": 4
              }
            }
          }
        ]
      }
    }
  },
  "advanced_auth": {
    "auth_flow_type": "oauth2.0",
    "predicate_key": ["credentials", "auth_type"],
    "predicate_value": "OAuth2.0",
    "oauth_config_specification": {
      "oauth_user_input_from_connector_config_specification": {
        "type": "object",
        "properties": {
          "host": {
            "type": "string",
            "path_in_connector_config": ["host"]
          }
        }
      },
      "complete_oauth_output_specification": {
        "type": "object",
        "additionalProperties": false,
        "properties": {
          "access_token": {
            "type": "string",
            "path_in_connector_config": ["credentials", "access_token"]
          },
          "refresh_token": {
            "type": "string",
            "path_in_connector_config": ["credentials", "refresh_token"]
          }
        }
      },
      "complete_oauth_server_input_specification": {
        "type": "object",
        "additionalProperties": false,
        "properties": {
          "client_id": {
            "type": "string"
          },
          "client_secret": {
            "type": "string"
          }
        }
      },
      "complete_oauth_server_output_specification": {
        "type": "object",
        "additionalProperties": false,
        "properties": {
          "client_id": {
            "type": "string",
            "path_in_connector_config": ["credentials", "client_id"]
          },
          "client_secret": {
            "type": "string",
            "path_in_connector_config": ["credentials", "client_secret"]
          }
        }
      }
    }
  }
}
