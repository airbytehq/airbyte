import org.apache.tools.ant.taskdefs.condition.Os

plugins {
    id 'airbyte-docker'
    id 'airbyte-python'
}

airbytePython {
    moduleDirectory 'normalization'
}

dependencies {
    project(':airbyte-connector-test-harnesses:acceptance-test-harness')
}

// we need to access the sshtunneling script from airbyte-workers for ssh support
def copySshScript = tasks.register('copySshScript', Copy) {
    from "${project(':airbyte-connector-test-harnesses:acceptance-test-harness').buildDir}/resources/main"
    into "${buildDir}"
    include "sshtunneling.sh"
}
copySshScript.configure {
    dependsOn project(':airbyte-connector-test-harnesses:acceptance-test-harness').tasks.named('processResources')
}

// make sure the copy task above worked (if it fails, it fails silently annoyingly)
def checkSshScriptCopy = tasks.register('checkSshScriptCopy') {
    doFirst {
        assert file("${buildDir}/sshtunneling.sh").exists() :
                "Copy of sshtunneling.sh failed, check that it is present in airbyte-workers."
    }
}
checkSshScriptCopy.configure {
    dependsOn copySshScript
}

tasks.named('airbyteDocker').configure {
    dependsOn checkSshScriptCopy
}
tasks.named('assemble').configure {
    dependsOn checkSshScriptCopy
}
tasks.named('check').configure {
    dependsOn checkSshScriptCopy
}

def customIntegrationTestPython = tasks.register('customIntegrationTestPython', PythonTask) {
    module = "pytest"
    command = "-s integration_tests"
}
customIntegrationTestPython.configure {
    dependsOn tasks.named('installTestReqs')
    dependsOn tasks.named('airbyteDocker')
}

static def getDockerfile(String customConnector) {
    return "${customConnector}.Dockerfile"
}

static def getDockerImageName(String customConnector) {
    return "airbyte/normalization-${customConnector}"
}

static def getImageNameWithTag(String customConnector) {
    return "${getDockerImageName(customConnector)}:dev"
}

def buildAirbyteDocker(String customConnector) {
    // def baseCommand = ['docker', 'build', '.', '-f', getDockerfile(customConnector), '-t', getImageNameWithTag(customConnector)]
    // As the base dbt image (https://hub.docker.com/r/fishtownanalytics/dbt/tags) we are using is only build for amd64, we need to use buildkit to force builds for your local environment
    // We are lucky that all the python code dbt uses is mutli-arch compatible

    def arch = 'linux/amd64'
    if (Os.isArch("aarch_64") || Os.isArch("aarch64")) {
        arch = 'linux/arm64'
    }

    def cmdArray = ['docker', 'buildx', 'build', '--load', '--platform', arch, '-f', getDockerfile(customConnector), '-t', getImageNameWithTag(customConnector), '.']
    // println("Building normalization container: " + cmdArray.join(" "))

    return {
        commandLine cmdArray
    }
}

[ 'airbyteDockerMSSql': 'mssql',
  'airbyteDockerMySql': 'mysql',
  'airbyteDockerOracle': 'oracle',
  'airbyteDockerClickhouse': 'clickhouse',
  'airbyteDockerSnowflake': 'snowflake',
  'airbyteDockerRedshift': 'redshift',
  'airbyteDockerTiDB': 'tidb',
  'airbyteDockerDuckDB': 'duckdb'
].forEach {taskName, customConnector ->
    def task = tasks.register(taskName, Exec) {
        configure buildAirbyteDocker(customConnector)
    }
    task.configure {
        dependsOn checkSshScriptCopy
        dependsOn tasks.named('assemble')
    }
    tasks.named('airbyteDocker').configure {
        dependsOn task
    }
}

def customIntegrationTestsCoverage = tasks.named('_customIntegrationTestsCoverage')
customIntegrationTestsCoverage.configure {
    dependsOn tasks.named('airbyteDocker')
}

[
        'bigquery',
        'mysql',
        'postgres',
        'redshift',
        'snowflake',
        'oracle',
        'mssql',
        'clickhouse',
        'tidb',
        'duckdb',
].each {destinationName ->
    def destinationProject = project(":airbyte-integrations:connectors:destination-$destinationName")
    customIntegrationTestPython.configure {
        dependsOn destinationProject.tasks.named('airbyteDocker')
    }
    // Not really sure what this task does differently from customIntegrationTestPython,
    // but it seems to also run integration tests and as such it depends on the docker images.
    customIntegrationTestsCoverage.configure {
        dependsOn destinationProject.tasks.named('airbyteDocker')
    }
}

// DATs have some additional tests that exercise normalization code paths,
// so we want to run these in addition to the base-normalization integration tests.
// If you add more items here, make sure to also to have CI fetch their credentials.
// See git history for an example.
// TODO reenable these - they're causing flakiness in our test results, need to figure that out
// integrationTest.dependsOn(":airbyte-integrations:connectors:destination-bigquery:integrationTest")
// integrationTest.dependsOn(":airbyte-integrations:connectors:destination-postgres:integrationTest")
// integrationTest.dependsOn(":airbyte-integrations:connectors:destination-snowflake:integrationTest")

tasks.named('customIntegrationTests').configure {
    dependsOn customIntegrationTestPython
}

// TODO fix and use https://github.com/airbytehq/airbyte/issues/3192 instead
def mypyCheck = tasks.register('mypyCheck', PythonTask) {
    module = "mypy"
    command = "normalization --config-file ${project.rootProject.file('pyproject.toml').absolutePath}"
}
tasks.named('airbytePythonChecks').configure { dependsOn mypyCheck }
